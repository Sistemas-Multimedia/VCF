{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LBT Demo: Block Sizes 16, 8, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LBT (Learned Block Transform)** es una transformada que el algoritmo \"aprende\" específicamente para cada imagen. En lugar de usar una transformada fija (como DCT), calcula cuál es la mejor transformada para esa imagen en particular.\n",
    "\n",
    "Todas las transformadas de compresión (DCT, DWT, etc.) se basan en unos datos estadísticos típicos que funcionan bien \"en general\". Pero cada imagen es diferente:\n",
    "\n",
    "- Una imagen de un paisaje tiene características muy distintas a una de texto\n",
    "- Una imagen con mucho ruido comprime diferente que una limpia\n",
    "- Las texturas, colores y patrones varían mucho\n",
    "\n",
    "**LBT aprende cuál es la transformada óptima para TU imagen**, lo que permite mejores resultados de compresión.\n",
    "\n",
    "1. **Divide la imagen en bloques**: Típicamente de 16×16, 8×8 o 4×4 píxeles\n",
    "2. **Analiza estadísticamente cada bloque**: Busca cuál es la transformada que mejor representa los datos de ese bloque\n",
    "3. **Usa PCA**: Específicamente, aplica **análisis de componentes principales (PCA)** a cada bloque para encontrar las direcciones de máxima varianza\n",
    "4. **Guarda la transformada aprendida**: Para que el decodificador sepa cómo descomprimir\n",
    "\n",
    "### PCA vs DCT\n",
    "\n",
    "| Aspecto | DCT | LBT (PCA) |\n",
    "|--------|-----|-----------|\n",
    "| **Adaptación** | Fija para todas las imágenes | Se aprende por imagen |\n",
    "| **Compresión** | Buena en general | Óptima para esa imagen |\n",
    "| **Complejidad** | Simple, rápido | Más cálculo, más lento |\n",
    "| **Overhead** | Ninguno | Hay que guardar la transformada |\n",
    "| **Uso típico** | JPEG, estándares | Investigación, aplicaciones personalizadas |\n",
    "\n",
    "### Cómo se Usa en VCF\n",
    "\n",
    "En **VCF (Video Compression Framework)**, LBT actúa como **transformada espacial alternativa**:\n",
    "\n",
    "```\n",
    "Imagen Original → Partición en Bloques → Aprender Transformada (PCA) → Cuantización → Codificación de Entropía → Almacenamiento\n",
    "                                              ↓\n",
    "Decodificación → Desaprender Transformada → Dequantización → Reconstrucción → Imagen Final\n",
    "```\n",
    "\n",
    "**Lo que consigues:**\n",
    "- **Compresión adaptada**: Cada bloque usa la transformada que mejor funciona para él\n",
    "- **Mejor relación compresión/distorsión**: Especialmente en imágenes con características específicas\n",
    "- **Análisis de patrones**: Permite ver qué transformadas \"aprende\" para diferentes tipos de contenido\n",
    "- **Flexibilidad de bloques**: Puedes experimentar con diferentes tamaños (16×16, 8×8, 4×4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación: Variando el Tamaño de Bloque\n",
    "\n",
    "Uno de los parámetros clave en LBT es el **tamaño de los bloques** en los que se divide la imagen. Cada tamaño tiene sus ventajas y desventajas:\n",
    "\n",
    "- **Bloques de 16×16**: Los bloques más grandes. Menos transformadas que guardar, lo que significa menos datos extra. Cada transformada es más \"general\" porque representa una zona más grande. Más rápido de procesar, pero menos preciso.\n",
    "\n",
    "- **Bloques de 8×8**: Tamaño intermedio. Más transformadas que guardar que con 16×16, pero menos que con 4×4. Punto medio entre precisión y velocidad.\n",
    "\n",
    "- **Bloques de 4×4**: Los bloques más pequeños. Máxima adaptación: cada bloque pequeño aprende su propia transformada. Pero significa muchas más transformadas que guardar, aumentando el overhead. Mucho más lento de procesar, pero más preciso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrantes del Proyecto\n",
    "\n",
    "- **Isabel Pelaya Galindo Ibáñez**\n",
    "- **Esther Ibáñez Mingorance**\n",
    "- **José Luis López García**\n",
    "- **Juan Rafael Madolell Usero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['matplotlib', 'scipy', 'bm3d']\n",
    "for package in packages:\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', package], check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/visualization.py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def show_images(original_path, encoded_path, decoded_path, title):\n",
    "    \"\"\"\n",
    "    Función para visualizar y comparar las imágenes original, codificada y decodificada.\n",
    "    \n",
    "    Parámetros:\n",
    "        original_path: ruta a la imagen original\n",
    "        encoded_path: ruta a la imagen codificada (coeficientes)\n",
    "        decoded_path: ruta a la imagen decodificada\n",
    "        title: título para la visualización\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    # Mostrar imagen original\n",
    "    if os.path.exists(original_path):\n",
    "        img = cv2.cvtColor(cv2.imread(original_path), cv2.COLOR_BGR2RGB)\n",
    "        axs[0].imshow(img)\n",
    "        axs[0].set_title(f'Original\\nTamaño: {os.path.getsize(original_path)/1024:.1f} KB')\n",
    "    else:\n",
    "        axs[0].text(0.5, 0.5, 'No encontrada', ha='center')\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    # Mostrar imagen codificada (Coeficientes)\n",
    "    # Nota: Se muestra el archivo de coeficientes como imagen. Puede parecer ruido o bloques.\n",
    "    if os.path.exists(encoded_path):\n",
    "        try:\n",
    "            # Intentar leer con OpenCV (maneja archivos TIF)\n",
    "            img_enc = cv2.imread(encoded_path, cv2.IMREAD_UNCHANGED)\n",
    "            if img_enc is not None:\n",
    "                if len(img_enc.shape) == 3:\n",
    "                     # Convertir BGR a RGB si es imagen de color\n",
    "                     img_enc = cv2.cvtColor(img_enc, cv2.COLOR_BGR2RGB)\n",
    "                # Mostrar los coeficientes sin normalización\n",
    "                axs[1].imshow(img_enc, cmap='gray')\n",
    "            else:\n",
    "                 axs[1].text(0.5, 0.5, 'No se pudo leer TIF', ha='center')\n",
    "        except Exception as e:\n",
    "             axs[1].text(0.5, 0.5, f'Error: {e}', ha='center')\n",
    "        \n",
    "        # Calcular y mostrar tamaños de archivos\n",
    "        weights_path = encoded_path.replace('.tif', '_weights.bin')\n",
    "        w_size = os.path.getsize(weights_path) if os.path.exists(weights_path) else 0\n",
    "        enc_size = os.path.getsize(encoded_path)\n",
    "        total_size = enc_size + w_size\n",
    "        axs[1].set_title(f'Coeficientes + Pesos\\nTIF: {enc_size/1024:.1f} KB | Pesos: {w_size/1024:.1f} KB\\nTotal: {total_size/1024:.1f} KB')\n",
    "    else:\n",
    "        axs[1].text(0.5, 0.5, 'No encontrada', ha='center')\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    # Mostrar imagen decodificada (reconstruida)\n",
    "    if os.path.exists(decoded_path):\n",
    "        img_dec = cv2.cvtColor(cv2.imread(decoded_path), cv2.COLOR_BGR2RGB)\n",
    "        axs[2].imshow(img_dec)\n",
    "        axs[2].set_title(f'Decodificada\\nTamaño: {os.path.getsize(decoded_path)/1024:.1f} KB')\n",
    "    else:\n",
    "        axs[2].text(0.5, 0.5, 'No encontrada', ha='center')\n",
    "    axs[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_rgb(path):\n",
    "    \"\"\"Carga una imagen en formato RGB.\"\"\"\n",
    "    if not os.path.exists(path): return np.zeros((10,10,3), dtype=np.uint8)\n",
    "    img = cv2.imread(path)\n",
    "    if img is None: return np.zeros((10,10,3), dtype=np.uint8)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def show_results_bm3d(img_name, original_path, filtered_paths):\n",
    "    \"\"\"Muestra los resultados: Original + 3 filtradas (BM3D).\"\"\"\n",
    "    # Configuración de niveles\n",
    "    levels = ['Baja', 'Media', 'Alta']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    \n",
    "    # Imagen Original\n",
    "    axes[0].imshow(load_rgb(original_path))\n",
    "    axes[0].set_title(f\"Original ({img_name})\", fontsize=12, fontweight='bold')\n",
    "    axes[0].axis('on')\n",
    "    axes[0].set_xticks([]); axes[0].set_yticks([])\n",
    "    \n",
    "    # Resultados Filtrados (BM3D)\n",
    "    for i in range(3):\n",
    "        if i < len(filtered_paths):\n",
    "            axes[i+1].imshow(load_rgb(filtered_paths[i]))\n",
    "            axes[i+1].set_title(f\"BM3D - {levels[i]}\", fontsize=12)\n",
    "            axes[i+1].axis('on')\n",
    "            axes[i+1].set_xticks([]); axes[i+1].set_yticks([])\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"Resultados: {img_name}\", fontsize=16, y=1.05)\n",
    "    plt.show()\n",
    "\n",
    "def show_results_nlm(img_name, original_path, filtered_paths):\n",
    "    \"\"\"Muestra los resultados: Original + 3 filtradas (NLM).\"\"\"\n",
    "    # Configuración de niveles\n",
    "    levels = ['Baja', 'Media', 'Alta']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    \n",
    "    # Imagen Original\n",
    "    axes[0].imshow(load_rgb(original_path))\n",
    "    axes[0].set_title(f\"Original ({img_name})\", fontsize=12, fontweight='bold')\n",
    "    axes[0].axis('on')\n",
    "    axes[0].set_xticks([]); axes[0].set_yticks([])\n",
    "    \n",
    "    # Resultados Filtrados (NLM)\n",
    "    for i in range(3):\n",
    "        if i < len(filtered_paths):\n",
    "            axes[i+1].imshow(load_rgb(filtered_paths[i]))\n",
    "            axes[i+1].set_title(f\"NLM - {levels[i]}\", fontsize=12)\n",
    "            axes[i+1].axis('on')\n",
    "            axes[i+1].set_xticks([]); axes[i+1].set_yticks([])\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"Resultados: {img_name}\", fontsize=16, y=1.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/LBT.py\n",
    "'''\n",
    "Transformada de Bloque Aprendida (LBT) usando un Autoencoder de 3 capas.\n",
    "\n",
    "Este módulo implementa un método de compresión de imágenes basado en KLT (Karhunen-Loève Transform)\n",
    "que aprende la transformada óptima para maximizar la compactación de energía en bloques de píxeles.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "import main\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.makedirs(\"/tmp\", exist_ok=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import tempfile\n",
    "import builtins\n",
    "\n",
    "# Create a valid temporary file path\n",
    "temp_desc_path = os.path.join(tempfile.gettempdir(), \"description.txt\")\n",
    "\n",
    "# Write the description to the valid temporary file\n",
    "with open(temp_desc_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(__doc__)\n",
    "\n",
    "# Monkeypatch open to redirect /tmp/description.txt to our valid temp file\n",
    "# This is necessary because parser.py (which we cannot edit) hardcodes /tmp/description.txt\n",
    "_original_open = builtins.open\n",
    "\n",
    "def _redirect_open(file, *args, **kwargs):\n",
    "    if file == \"/tmp/description.txt\":\n",
    "        return _original_open(temp_desc_path, *args, **kwargs)\n",
    "    return _original_open(file, *args, **kwargs)\n",
    "\n",
    "builtins.open = _redirect_open\n",
    "\n",
    "try:\n",
    "    import parser\n",
    "finally:\n",
    "    # Restore original open\n",
    "    builtins.open = _original_open\n",
    "import importlib\n",
    "import struct\n",
    "import cv2\n",
    "\n",
    "# Importar transformaciones de color\n",
    "# pip install \"color_transforms @ git+https://github.com/vicente-gonzalez-ruiz/color_transforms\"\n",
    "from color_transforms.YCoCg import from_RGB  # type: ignore\n",
    "from color_transforms.YCoCg import to_RGB  # type: ignore\n",
    "\n",
    "# Importar funciones DCT (Transformada Coseno Discreta) para el procesamiento de bloques\n",
    "# pip install \"DCT2D @ git+https://github.com/vicente-gonzalez-ruiz/DCT2D\"\n",
    "from DCT2D.block_DCT import get_subbands  # type: ignore\n",
    "from DCT2D.block_DCT import get_blocks  # type: ignore\n",
    "\n",
    "# Parámetros por defecto\n",
    "default_block_size = 8\n",
    "default_CT = \"YCoCg\"\n",
    "perceptual_quantization = False\n",
    "disable_subbands = False\n",
    "\n",
    "parser.parser_encode.add_argument(\"-B\", \"--block_size_DCT\", type=parser.int_or_str, help=f\"Tamaño de bloque (por defecto: {default_block_size})\", default=default_block_size)\n",
    "parser.parser_encode.add_argument(\"-t\", \"--color_transform\", type=parser.int_or_str, help=f\"Transformada de color (por defecto: \\\"{default_CT}\\\")\", default=default_CT)\n",
    "parser.parser_encode.add_argument(\"-x\", \"--disable_subbands\", action='store_true', help=f\"Desactivar reordenamiento de coeficientes en subbandas (por defecto: \\\"{disable_subbands}\\\")\", default=disable_subbands)\n",
    "\n",
    "parser.parser_decode.add_argument(\"-B\", \"--block_size_DCT\", type=parser.int_or_str, help=f\"Tamaño de bloque (por defecto: {default_block_size})\", default=default_block_size)\n",
    "parser.parser_decode.add_argument(\"-t\", \"--color_transform\", type=parser.int_or_str, help=f\"Transformada de color (por defecto: \\\"{default_CT}\\\")\", default=default_CT)\n",
    "parser.parser_decode.add_argument(\"-x\", \"--disable_subbands\", action='store_true', help=f\"Desactivar reordenamiento de coeficientes en subbandas (por defecto: \\\"{disable_subbands}\\\")\", default=disable_subbands)\n",
    "\n",
    "\n",
    "args = parser.parser.parse_known_args()[0]\n",
    "CT = importlib.import_module(args.color_transform)\n",
    "\n",
    "class LBT_Autoencoder:\n",
    "    \"\"\"\n",
    "    Autoencoder de 3 capas que aprende la transformada lineal óptima (KLT - Transformada Karhunen-Loève)\n",
    "    para maximizar la ganancia de codificación (compactación de energía).\n",
    "    \n",
    "    La idea es que la KLT descorrelaciona los datos y concentra la energía en pocos coeficientes,\n",
    "    mejorando la tasa de compresión respecto a transformadas fijas como DCT.\n",
    "    \"\"\"\n",
    "    def __init__(self, block_size):\n",
    "        \"\"\"\n",
    "        Inicializa el autoencoder con un tamaño de bloque específico.\n",
    "        \n",
    "        Parámetros:\n",
    "            block_size: Tamaño del bloque (debe ser entero positivo)\n",
    "            \n",
    "        Excepciones:\n",
    "            ValueError: Si block_size no es entero positivo\n",
    "        \"\"\"\n",
    "        if not isinstance(block_size, (int, np.integer)):\n",
    "            raise ValueError(f\"block_size debe ser un entero, recibido: {type(block_size)}\")\n",
    "        if block_size <= 0:\n",
    "            raise ValueError(f\"block_size debe ser positivo, recibido: {block_size}\")\n",
    "        \n",
    "        self.block_size = block_size\n",
    "        self.input_dim = block_size * block_size\n",
    "        self.weights = None  # Matriz de transformada aprendida (pesos hacia adelante)\n",
    "\n",
    "    def train(self, patches):\n",
    "        \"\"\"\n",
    "        Aprende los pesos óptimos a partir de parches de la imagen.\n",
    "        \n",
    "        Utiliza Análisis de Componentes Principales (PCA) / Transformada Karhunen-Loève\n",
    "        para encontrar los vectores propios de la matriz de covarianza de los datos.\n",
    "        Estos vectores propios forman la base ortogonal que maximiza la compactación de energía.\n",
    "        \n",
    "        Parámetros:\n",
    "            patches: arreglo de forma (N_parches, block_size, block_size) o (N_parches, input_dim)\n",
    "            \n",
    "        Excepciones:\n",
    "            TypeError: Si patches no es un arreglo numpy\n",
    "            ValueError: Si patches tiene forma incompatible\n",
    "            np.linalg.LinAlgError: Si la matriz de covarianza es singular\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validar tipo de entrada\n",
    "            if not isinstance(patches, np.ndarray):\n",
    "                raise TypeError(f\"patches debe ser un arreglo numpy, recibido: {type(patches)}\")\n",
    "            \n",
    "            # Validar número de dimensiones\n",
    "            if patches.ndim not in [2, 3]:\n",
    "                raise ValueError(f\"patches debe tener 2 o 3 dimensiones, recibido: {patches.ndim}\")\n",
    "            \n",
    "            # Aplanar los parches si es necesario\n",
    "            if patches.ndim == 3:\n",
    "                N, H, W = patches.shape\n",
    "                if H != self.block_size or W != self.block_size:\n",
    "                    raise ValueError(f\"Forma de bloque esperada: ({self.block_size}, {self.block_size}), recibida: ({H}, {W})\")\n",
    "                X = patches.reshape(-1, self.input_dim)\n",
    "            else:\n",
    "                X = patches\n",
    "                if X.shape[1] != self.input_dim:\n",
    "                    raise ValueError(f\"Dimensión esperada: {self.input_dim}, recibida: {X.shape[1]}\")\n",
    "            \n",
    "            # Validar número de parches\n",
    "            if X.shape[0] < 2:\n",
    "                logging.warning(f\"Número de parches muy pequeño ({X.shape[0]}). Se requieren al menos 2 parches para calcular covarianza confiable.\")\n",
    "            \n",
    "            # Validar que hay datos válidos\n",
    "            if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n",
    "                raise ValueError(\"Los parches contienen valores NaN o infinitos\")\n",
    "            \n",
    "            # Calcular la matriz de covarianza: C = (X^T * X) / N\n",
    "            # La covarianza describe cómo se distribuye la varianza en los datos\n",
    "            C = np.cov(X, rowvar=False)\n",
    "            \n",
    "            # Validar covarianza\n",
    "            if C.ndim != 2 or C.shape[0] != C.shape[1]:\n",
    "                raise ValueError(f\"Covarianza debe ser cuadrada, forma: {C.shape}\")\n",
    "            \n",
    "            # Descomposición en valores y vectores propios\n",
    "            # eigh se utiliza para matrices simétricas/Hermitianas (la covarianza lo es)\n",
    "            # Retorna autovalores (w) y autovectores (v) ordenados en forma ascendente\n",
    "            w, v = np.linalg.eigh(C)\n",
    "            \n",
    "            # Validar resultados de eigh\n",
    "            if np.any(np.isnan(w)) or np.any(np.isnan(v)):\n",
    "                raise np.linalg.LinAlgError(\"Descomposición en valores/vectores propios produjo NaN\")\n",
    "            \n",
    "            # Ordenar los autovectores por autovalores descendentes (mayor energía primero)\n",
    "            # Los autovalores grandes corresponden a direcciones con alta varianza\n",
    "            idx = np.argsort(w)[::-1]\n",
    "            self.weights = v[:, idx].T  # Las filas son autovectores. Forma: (D, D)\n",
    "            \n",
    "            logging.debug(f\"LBT entrenado correctamente con {X.shape[0]} parches de tamaño {self.block_size}x{self.block_size}\")\n",
    "            \n",
    "        except TypeError as e:\n",
    "            logging.error(f\"Error de tipo en train: {e}\")\n",
    "            raise\n",
    "        except ValueError as e:\n",
    "            logging.error(f\"Error de valor en train: {e}\")\n",
    "            raise\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            logging.error(f\"Error de álgebra lineal en train: {e}\")\n",
    "            raise\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        \"\"\"\n",
    "        Establece manualmente los pesos de la transformada.\n",
    "        \n",
    "        Parámetros:\n",
    "            weights: Matriz de pesos de forma (input_dim, input_dim)\n",
    "            \n",
    "        Excepciones:\n",
    "            TypeError: Si weights no es un arreglo numpy\n",
    "            ValueError: Si weights tiene forma incorrecta\n",
    "        \"\"\"\n",
    "        if not isinstance(weights, np.ndarray):\n",
    "            raise TypeError(f\"weights debe ser un arreglo numpy, recibido: {type(weights)}\")\n",
    "        \n",
    "        if weights.shape != (self.input_dim, self.input_dim):\n",
    "            raise ValueError(f\"weights debe tener forma ({self.input_dim}, {self.input_dim}), recibida: {weights.shape}\")\n",
    "        \n",
    "        if np.any(np.isnan(weights)) or np.any(np.isinf(weights)):\n",
    "            raise ValueError(\"weights contiene valores NaN o infinitos\")\n",
    "        \n",
    "        self.weights = weights\n",
    "        logging.debug(f\"Pesos de transformada establecidos correctamente\")\n",
    "\n",
    "    def get_weights(self):\n",
    "        \"\"\"\n",
    "        Retorna los pesos aprendidos de la transformada.\n",
    "        \n",
    "        Retorna:\n",
    "            Matriz de pesos, o None si no ha sido entrenado\n",
    "            \n",
    "        Excepciones:\n",
    "            RuntimeError: Si se intenta obtener pesos sin entrenar primero\n",
    "        \"\"\"\n",
    "        if self.weights is None:\n",
    "            raise RuntimeError(\"Los pesos no han sido inicializados. Entrene el autoencoder primero.\")\n",
    "        return self.weights\n",
    "\n",
    "    def forward(self, patches):\n",
    "        \"\"\"\n",
    "        Paso hacia adelante (Codificar / Transformar).\n",
    "        Aplica la transformada KLT aprendida a los parches.\n",
    "        \n",
    "        Entrada: arreglo de forma (N, block_size, block_size)\n",
    "        Salida: arreglo de forma (N, block_size, block_size) con coeficientes transformados\n",
    "        \n",
    "        Excepciones:\n",
    "            RuntimeError: Si no se ha entrenado previamente\n",
    "            ValueError: Si la forma del parche es incorrecta\n",
    "        \"\"\"\n",
    "        if self.weights is None:\n",
    "            raise RuntimeError(\"Autoencoder no entrenado. Ejecute train() primero.\")\n",
    "        \n",
    "        try:\n",
    "            if patches.ndim != 3:\n",
    "                raise ValueError(f\"patches debe ser 3D, recibido: {patches.ndim}D\")\n",
    "            \n",
    "            N, H, W = patches.shape\n",
    "            if H != self.block_size or W != self.block_size:\n",
    "                raise ValueError(f\"Forma de bloque esperada: ({self.block_size}, {self.block_size}), recibida: ({H}, {W})\")\n",
    "            \n",
    "            X = patches.reshape(N, -1)  # (N, D)\n",
    "            \n",
    "            # Verificar NaN/Inf\n",
    "            if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n",
    "                raise ValueError(\"patches contiene valores NaN o infinitos\")\n",
    "            \n",
    "            # Transformar: C = X @ W^T \n",
    "            coeffs = np.dot(X, self.weights.T)\n",
    "            \n",
    "            if np.any(np.isnan(coeffs)):\n",
    "                raise ValueError(\"Coeficientes transformados contienen NaN\")\n",
    "            \n",
    "            return coeffs.reshape(N, H, W)\n",
    "            \n",
    "        except ValueError as e:\n",
    "            logging.error(f\"Error en forward: {e}\")\n",
    "            raise\n",
    "\n",
    "    def backward(self, coeffs):\n",
    "        \"\"\"\n",
    "        Paso hacia atrás (Decodificar / Transformada Inversa).\n",
    "        Reconstruye los parches originales desde los coeficientes transformados.\n",
    "        \n",
    "        Entrada: arreglo de forma (N, block_size, block_size) con coeficientes\n",
    "        Salida: arreglo de forma (N, block_size, block_size) reconstruido\n",
    "        \n",
    "        Excepciones:\n",
    "            RuntimeError: Si no se ha entrenado previamente\n",
    "            ValueError: Si la forma de los coeficientes es incorrecta\n",
    "        \"\"\"\n",
    "        if self.weights is None:\n",
    "            raise RuntimeError(\"Autoencoder no entrenado. Ejecute train() primero.\")\n",
    "        \n",
    "        try:\n",
    "            if coeffs.ndim != 3:\n",
    "                raise ValueError(f\"coeffs debe ser 3D, recibido: {coeffs.ndim}D\")\n",
    "            \n",
    "            N, H, W = coeffs.shape\n",
    "            if H != self.block_size or W != self.block_size:\n",
    "                raise ValueError(f\"Forma de bloque esperada: ({self.block_size}, {self.block_size}), recibida: ({H}, {W})\")\n",
    "            \n",
    "            Y = coeffs.reshape(N, -1)\n",
    "            \n",
    "            # Verificar NaN/Inf\n",
    "            if np.any(np.isnan(Y)) or np.any(np.isinf(Y)):\n",
    "                raise ValueError(\"coeffs contiene valores NaN o infinitos\")\n",
    "            \n",
    "            # Inversa: Rec = Y @ W\n",
    "            # Dado que W es ortogonal, W^(-1) = W^T.\n",
    "            rec = np.dot(Y, self.weights)\n",
    "            \n",
    "            if np.any(np.isnan(rec)):\n",
    "                raise ValueError(\"Reconstrucción contiene NaN\")\n",
    "            \n",
    "            return rec.reshape(N, H, W)\n",
    "            \n",
    "        except ValueError as e:\n",
    "            logging.error(f\"Error en backward: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "class CoDec(CT.CoDec):\n",
    "    \"\"\"\n",
    "    Codificador/Decodificador que utiliza la Transformada de Bloque Aprendida (LBT).\n",
    "    \n",
    "    Extiende la clase CoDec del módulo de transformada de color seleccionada.\n",
    "    Implementa codificación y decodificación de imágenes usando LBT seguida de\n",
    "    cuantización y compresión de entropía.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        \"\"\"\n",
    "        Inicializa el codificador/decodificador con los argumentos de configuración.\n",
    "        \n",
    "        Parámetros:\n",
    "            args: Argumentos de línea de comandos\n",
    "            \n",
    "        Excepciones:\n",
    "            AttributeError: Si faltan atributos requeridos en args\n",
    "            ValueError: Si block_size es inválido\n",
    "        \"\"\"\n",
    "        logging.debug(\"trace\")\n",
    "        try:\n",
    "            # Validar argumentos requeridos\n",
    "            if not hasattr(args, 'block_size_DCT'):\n",
    "                raise AttributeError(\"args debe tener atributo 'block_size_DCT'\")\n",
    "            \n",
    "            block_size = args.block_size_DCT\n",
    "            if isinstance(block_size, str):\n",
    "                try:\n",
    "                    block_size = int(block_size)\n",
    "                except ValueError:\n",
    "                    raise ValueError(f\"block_size_DCT no puede convertirse a entero: {block_size}\")\n",
    "            \n",
    "            if not isinstance(block_size, (int, np.integer)) or block_size <= 0:\n",
    "                raise ValueError(f\"block_size_DCT debe ser entero positivo, recibido: {block_size}\")\n",
    "            \n",
    "            super().__init__(args)\n",
    "            self.block_size = block_size\n",
    "            self.lbt = LBT_Autoencoder(self.block_size)\n",
    "            \n",
    "            # Establecer desplazamiento según el cuantizador usado\n",
    "            # El cuantizador \"deadzone\" requiere un desplazamiento de 128 para centrar valores\n",
    "            if hasattr(args, 'quantizer') and args.quantizer == \"deadzone\":\n",
    "                self.offset = 128\n",
    "            else:\n",
    "                self.offset = 0\n",
    "                \n",
    "            logging.debug(f\"CoDec inicializado: block_size={self.block_size}, offset={self.offset}\")\n",
    "            \n",
    "        except (AttributeError, ValueError) as e:\n",
    "            logging.error(f\"Error en inicialización de CoDec: {e}\")\n",
    "            raise\n",
    "\n",
    "    def pad_and_center_to_multiple_of_block_size(self, img):\n",
    "        \"\"\"\n",
    "        Rellena la imagen con ceros para que sus dimensiones sean múltiplos del tamaño de bloque.\n",
    "        \n",
    "        Este paso es necesario porque la transformada de bloque requiere que la imagen\n",
    "        sea divisible por el tamaño de bloque.\n",
    "        \n",
    "        Parámetros:\n",
    "            img: imagen de entrada de forma (altura, ancho, canales)\n",
    "            \n",
    "        Retorna:\n",
    "            Imagen rellenada con forma que es múltiplo del tamaño de bloque\n",
    "            \n",
    "        Excepciones:\n",
    "            ValueError: Si la imagen tiene formato incorrecto\n",
    "            TypeError: Si la imagen no es un arreglo numpy\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not isinstance(img, np.ndarray):\n",
    "                raise TypeError(f\"img debe ser un arreglo numpy, recibido: {type(img)}\")\n",
    "            \n",
    "            if img.ndim != 3:\n",
    "                raise ValueError(f\"La imagen debe ser un arreglo 3D (altura, ancho, canales), recibido: {img.ndim}D\")\n",
    "            \n",
    "            if img.shape[2] != 3:\n",
    "                logging.warning(f\"Se esperan 3 canales, recibidos: {img.shape[2]}\")\n",
    "\n",
    "            self.original_shape = img.shape\n",
    "            height, width, channels = img.shape\n",
    "            \n",
    "            # Validar dimensiones\n",
    "            if height <= 0 or width <= 0 or channels <= 0:\n",
    "                raise ValueError(f\"Dimensiones de imagen inválidas: {img.shape}\")\n",
    "            \n",
    "            if self.block_size <= 0:\n",
    "                raise ValueError(f\"block_size inválido: {self.block_size}\")\n",
    "\n",
    "            # Calcular las dimensiones de destino (múltiplos del tamaño de bloque)\n",
    "            target_height = (height + self.block_size - 1) // self.block_size * self.block_size\n",
    "            target_width = (width + self.block_size - 1) // self.block_size * self.block_size\n",
    "\n",
    "            pad_height = target_height - height\n",
    "            pad_width = target_width - width\n",
    "\n",
    "            # Distribuir el relleno equitativamente entre arriba/abajo e izquierda/derecha\n",
    "            pad_top = pad_height // 2\n",
    "            pad_bottom = pad_height - pad_top\n",
    "            pad_left = pad_width // 2\n",
    "            pad_right = pad_width - pad_left\n",
    "\n",
    "            # Aplicar el relleno\n",
    "            padded_img = np.pad(\n",
    "                img,\n",
    "                ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)),\n",
    "                mode='constant',\n",
    "                constant_values=0\n",
    "            )\n",
    "            \n",
    "            logging.debug(f\"Imagen rellenada: {img.shape} -> {padded_img.shape}\")\n",
    "            return padded_img\n",
    "            \n",
    "        except (TypeError, ValueError) as e:\n",
    "            logging.error(f\"Error en pad_and_center_to_multiple_of_block_size: {e}\")\n",
    "            raise\n",
    "\n",
    "    def remove_padding(self, padded_img):\n",
    "        \"\"\"\n",
    "        Elimina el relleno agregado durante la codificación.\n",
    "        \n",
    "        Restaura la imagen a sus dimensiones originales.\n",
    "        \n",
    "        Parámetros:\n",
    "            padded_img: imagen rellenada\n",
    "            \n",
    "        Retorna:\n",
    "            Imagen sin relleno con las dimensiones originales\n",
    "            \n",
    "        Excepciones:\n",
    "            ValueError: Si las dimensiones son inconsistentes\n",
    "            RuntimeError: Si original_shape no ha sido establecido\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not hasattr(self, 'original_shape') or self.original_shape is None:\n",
    "                raise RuntimeError(\"original_shape no ha sido establecido. Ejecute pad_and_center_to_multiple_of_block_size primero.\")\n",
    "            \n",
    "            if not isinstance(padded_img, np.ndarray):\n",
    "                raise ValueError(\"padded_img debe ser un arreglo numpy\")\n",
    "            \n",
    "            original_height, original_width, _  = self.original_shape\n",
    "            padded_height, padded_width, _ = padded_img.shape\n",
    "\n",
    "            pad_height = padded_height - original_height\n",
    "            pad_width = padded_width - original_width\n",
    "            \n",
    "            if pad_height < 0 or pad_width < 0:\n",
    "                raise ValueError(f\"Imagen rellenada más pequeña que original: original={self.original_shape}, padded={padded_img.shape}\")\n",
    "\n",
    "            pad_top = pad_height // 2\n",
    "            pad_left = pad_width // 2\n",
    "\n",
    "            unpadded_img = padded_img[\n",
    "                pad_top:pad_top + original_height,\n",
    "                pad_left:pad_left + original_width,\n",
    "                :\n",
    "            ]\n",
    "            \n",
    "            if unpadded_img.shape != self.original_shape:\n",
    "                raise ValueError(f\"Dimensiones de salida incorrectas: esperado {self.original_shape}, obtenido {unpadded_img.shape}\")\n",
    "            \n",
    "            logging.debug(f\"Padding removido: {padded_img.shape} -> {unpadded_img.shape}\")\n",
    "            return unpadded_img\n",
    "            \n",
    "        except (ValueError, RuntimeError) as e:\n",
    "            logging.error(f\"Error en remove_padding: {e}\")\n",
    "            raise\n",
    "\n",
    "    def encode_fn(self, in_fn, out_fn):\n",
    "        \"\"\"\n",
    "        Codifica una imagen utilizando LBT.\n",
    "        \n",
    "        Proceso:\n",
    "        1. Lee la imagen\n",
    "        2. Rellena a múltiplos del tamaño de bloque\n",
    "        3. Aplica transformada de color\n",
    "        4. Entrena y aplica LBT para cada canal\n",
    "        5. Reordena coeficientes en subbandas (opcional)\n",
    "        6. Cuantiza los coeficientes\n",
    "        7. Comprime usando compresión de entropía\n",
    "        \n",
    "        Parámetros:\n",
    "            in_fn: ruta del archivo de imagen original\n",
    "            out_fn: ruta del archivo de salida codificado\n",
    "            \n",
    "        Excepciones:\n",
    "            FileNotFoundError: Si el archivo de entrada no existe\n",
    "            IOError: Si hay problemas al leer o escribir archivos\n",
    "            ValueError: Si la imagen está dañada o es inválida\n",
    "        \"\"\"\n",
    "        logging.debug(\"trace\")\n",
    "        \n",
    "        try:\n",
    "            # Validar rutas\n",
    "            if not isinstance(in_fn, str):\n",
    "                raise ValueError(f\"in_fn debe ser string, recibido: {type(in_fn)}\")\n",
    "            if not isinstance(out_fn, str):\n",
    "                raise ValueError(f\"out_fn debe ser string, recibido: {type(out_fn)}\")\n",
    "            \n",
    "            # Validar que el archivo existe\n",
    "            if not os.path.exists(in_fn):\n",
    "                raise FileNotFoundError(f\"Archivo de entrada no encontrado: {in_fn}\")\n",
    "            \n",
    "            # Validar permisos de lectura\n",
    "            if not os.access(in_fn, os.R_OK):\n",
    "                raise PermissionError(f\"Permiso denegado para leer: {in_fn}\")\n",
    "            \n",
    "            # Validar permisos de escritura en directorio de salida\n",
    "            out_dir = os.path.dirname(out_fn) or \".\"\n",
    "            if not os.access(out_dir, os.W_OK):\n",
    "                raise PermissionError(f\"Permiso denegado para escribir en: {out_dir}\")\n",
    "            \n",
    "            # Leer imagen y convertir a punto flotante\n",
    "            try:\n",
    "                img = self.encode_read_fn(in_fn).astype(np.float32)\n",
    "            except Exception as e:\n",
    "                raise IOError(f\"Error al leer imagen: {in_fn}: {e}\")\n",
    "            \n",
    "            if img is None or img.size == 0:\n",
    "                raise ValueError(f\"Imagen vacía o inválida: {in_fn}\")\n",
    "            \n",
    "            logging.info(f\"Imagen leída: forma={img.shape}\")\n",
    "            \n",
    "            # Rellenar la imagen\n",
    "            self.original_shape = img.shape\n",
    "            padded_img = self.pad_and_center_to_multiple_of_block_size(img)\n",
    "            \n",
    "            # Guardar las dimensiones originales para la decodificación\n",
    "            try:\n",
    "                with open(f\"{out_fn}_shape.bin\", \"wb\") as file:\n",
    "                    file.write(struct.pack(\"iii\", *self.original_shape))\n",
    "            except IOError as e:\n",
    "                raise IOError(f\"Error al escribir archivo de dimensiones: {out_fn}_shape.bin: {e}\")\n",
    "                \n",
    "            img = padded_img\n",
    "            # Aplicar desplazamiento para centrar valores\n",
    "            img -= self.offset\n",
    "            \n",
    "            # Transformada de color (RGB -> YCoCg u otro espacio de color)\n",
    "            try:\n",
    "                CT_img = from_RGB(img)  # Forma: (H, W, 3)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error en transformada de color: {e}\")\n",
    "            \n",
    "            H, W, C = CT_img.shape\n",
    "            \n",
    "            # Preparar para LBT\n",
    "            # Extraer todos los bloques y entrenar la LBT\n",
    "            # Se utiliza una LBT independiente para cada canal para mejor decorrelación\n",
    "            \n",
    "            transformed_channels = []\n",
    "            lbt_weights = []\n",
    "            \n",
    "            # Procesar cada canal de color independientemente\n",
    "            for c in range(C):\n",
    "                try:\n",
    "                    channel = CT_img[:, :, c]\n",
    "                    \n",
    "                    # Extraer parches (bloques no superpuestos)\n",
    "                    # channel tiene forma (H, W) donde H, W son múltiplos de block_size\n",
    "                    \n",
    "                    n_blocks_y = H // self.block_size\n",
    "                    n_blocks_x = W // self.block_size\n",
    "                    \n",
    "                    if n_blocks_y <= 0 or n_blocks_x <= 0:\n",
    "                        raise ValueError(f\"Número de bloques inválido: ({n_blocks_y}, {n_blocks_x})\")\n",
    "                    \n",
    "                    # Remodelar a (ny, nx, b, b) y luego a (N_bloques, b, b)\n",
    "                    patches = channel.reshape(n_blocks_y, self.block_size, n_blocks_x, self.block_size).swapaxes(1, 2).reshape(-1, self.block_size, self.block_size)\n",
    "                    \n",
    "                    # Entrenar LBT con los parches de este canal\n",
    "                    lbt = LBT_Autoencoder(self.block_size)\n",
    "                    lbt.train(patches)\n",
    "                    weights = lbt.get_weights()\n",
    "                    lbt_weights.append(weights)\n",
    "                    \n",
    "                    # Aplicar la transformada LBT hacia adelante\n",
    "                    coeffs_patches = lbt.forward(patches)\n",
    "                    \n",
    "                    # Remodelar los coeficientes de vuelta a imagen\n",
    "                    coeffs_img = coeffs_patches.reshape(n_blocks_y, n_blocks_x, self.block_size, self.block_size).swapaxes(1, 2).reshape(H, W)\n",
    "                    transformed_channels.append(coeffs_img)\n",
    "                    \n",
    "                    logging.debug(f\"Canal {c} procesado: {patches.shape[0]} bloques\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    raise ValueError(f\"Error procesando canal {c}: {e}\")\n",
    "            \n",
    "            # Combinar los canales transformados\n",
    "            LBT_img = np.stack(transformed_channels, axis=2)\n",
    "            lbt_weights = np.array(lbt_weights, dtype=np.float32)  # Forma: (3, D, D)\n",
    "            \n",
    "            # Guardar los pesos aprendidos para la decodificación\n",
    "            try:\n",
    "                with open(f\"{out_fn}_weights.bin\", \"wb\") as f:\n",
    "                    f.write(lbt_weights.tobytes())\n",
    "            except IOError as e:\n",
    "                raise IOError(f\"Error al escribir archivo de pesos: {out_fn}_weights.bin: {e}\")\n",
    "                \n",
    "            # Reordenar coeficientes en subbandas (agrupar por frecuencia)\n",
    "            try:\n",
    "                if args.disable_subbands:\n",
    "                    decom_img = LBT_img\n",
    "                else:\n",
    "                    decom_img = get_subbands(LBT_img, self.block_size, self.block_size)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error en procesamiento de subbandas: {e}\")\n",
    "                \n",
    "            # Cuantizar los coeficientes para reducir la precisión\n",
    "            try:\n",
    "                decom_k = self.quantize_decom(decom_img)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error en cuantización: {e}\")\n",
    "            \n",
    "            decom_k += self.offset\n",
    "            \n",
    "            # Verificar y advertir si hay valores fuera de rango\n",
    "            if self.args.debug:\n",
    "                if np.max(decom_k) > 255:\n",
    "                    logging.warning(f\"decom_k max={np.max(decom_k)}\")\n",
    "                if np.min(decom_k) < 0:\n",
    "                    logging.warning(f\"decom_k min={np.min(decom_k)}\")\n",
    "                    \n",
    "            # Aplicar compresión de entropía (Huffman, zlib, etc.)\n",
    "            decom_k = decom_k.astype(np.uint8)\n",
    "            try:\n",
    "                decom_k = self.compress(decom_k)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error en compresión de entropía: {e}\")\n",
    "            \n",
    "            # Escribir el flujo de código comprimido\n",
    "            try:\n",
    "                output_size = self.encode_write_fn(decom_k, out_fn)\n",
    "            except Exception as e:\n",
    "                raise IOError(f\"Error al escribir archivo codificado: {out_fn}: {e}\")\n",
    "            \n",
    "            logging.info(f\"Codificación completada: tamaño salida = {output_size} bytes\")\n",
    "            return output_size\n",
    "            \n",
    "        except (FileNotFoundError, IOError, PermissionError, ValueError) as e:\n",
    "            logging.error(f\"Error en encode_fn: {e}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error inesperado en encode_fn: {e}\")\n",
    "            raise\n",
    "\n",
    "    def decode_fn(self, in_fn, out_fn):\n",
    "        \"\"\"\n",
    "        Decodifica una imagen codificada con LBT.\n",
    "        \n",
    "        Proceso inverso a encode_fn:\n",
    "        1. Lee el flujo de código comprimido\n",
    "        2. Descomprime\n",
    "        3. Deshace la cuantización\n",
    "        4. Restaura los bloques desde subbandas\n",
    "        5. Aplica transformada inversa LBT para cada canal\n",
    "        6. Aplica transformada de color inversa\n",
    "        7. Elimina el relleno\n",
    "        8. Escribe la imagen decodificada\n",
    "        \n",
    "        Parámetros:\n",
    "            in_fn: ruta del archivo codificado\n",
    "            out_fn: ruta del archivo de salida decodificado\n",
    "            \n",
    "        Excepciones:\n",
    "            FileNotFoundError: Si falta alguno de los archivos necesarios\n",
    "            IOError: Si hay problemas al leer o escribir archivos\n",
    "            ValueError: Si los datos están dañados o son inválidos\n",
    "        \"\"\"\n",
    "        logging.debug(\"trace\")\n",
    "        \n",
    "        try:\n",
    "            # Validar rutas\n",
    "            if not isinstance(in_fn, str):\n",
    "                raise ValueError(f\"in_fn debe ser string, recibido: {type(in_fn)}\")\n",
    "            if not isinstance(out_fn, str):\n",
    "                raise ValueError(f\"out_fn debe ser string, recibido: {type(out_fn)}\")\n",
    "            \n",
    "            # Validar que los archivos existen\n",
    "            files_to_check = [in_fn + \".tif\", f\"{in_fn}_shape.bin\", f\"{in_fn}_weights.bin\"]\n",
    "            for file_path in files_to_check:\n",
    "                if not os.path.exists(file_path):\n",
    "                    raise FileNotFoundError(f\"Archivo necesario no encontrado: {file_path}\")\n",
    "                if not os.access(file_path, os.R_OK):\n",
    "                    raise PermissionError(f\"Permiso denegado para leer: {file_path}\")\n",
    "            \n",
    "            # Validar permisos de escritura en directorio de salida\n",
    "            out_dir = os.path.dirname(out_fn) or \".\"\n",
    "            if not os.access(out_dir, os.W_OK):\n",
    "                raise PermissionError(f\"Permiso denegado para escribir en: {out_dir}\")\n",
    "            \n",
    "            # Leer y descomprimir el flujo de código\n",
    "            try:\n",
    "                decom_k = self.decode_read_fn(in_fn)\n",
    "            except Exception as e:\n",
    "                raise IOError(f\"Error al leer archivo codificado: {in_fn}: {e}\")\n",
    "            \n",
    "            if decom_k is None or len(decom_k) == 0:\n",
    "                raise ValueError(f\"Archivo codificado vacío o inválido: {in_fn}\")\n",
    "            \n",
    "            # Leer las dimensiones originales\n",
    "            try:\n",
    "                with open(f\"{in_fn}_shape.bin\", \"rb\") as file:\n",
    "                    data = file.read(12)\n",
    "                    if len(data) != 12:\n",
    "                        raise ValueError(\"Archivo de dimensiones corrupto (tamaño incorrecto)\")\n",
    "                    self.original_shape = struct.unpack(\"iii\", data)\n",
    "            except (IOError, struct.error) as e:\n",
    "                raise IOError(f\"Error al leer archivo de dimensiones: {in_fn}_shape.bin: {e}\")\n",
    "            \n",
    "            logging.debug(f\"Dimensiones originales: {self.original_shape}\")\n",
    "            \n",
    "            # Leer los pesos aprendidos de la LBT\n",
    "            try:\n",
    "                dim = self.block_size * self.block_size\n",
    "                with open(f\"{in_fn}_weights.bin\", \"rb\") as f:\n",
    "                    weights_data = f.read()\n",
    "                    expected_size = 3 * dim * dim * 4  # 3 canales, dim x dim, float32 (4 bytes)\n",
    "                    if len(weights_data) != expected_size:\n",
    "                        raise ValueError(f\"Archivo de pesos corrupto: tamaño esperado {expected_size}, recibido {len(weights_data)}\")\n",
    "                    lbt_weights = np.frombuffer(weights_data, dtype=np.float32).reshape(3, dim, dim)\n",
    "            except (IOError, ValueError, struct.error) as e:\n",
    "                raise IOError(f\"Error al leer archivo de pesos: {in_fn}_weights.bin: {e}\")\n",
    "            \n",
    "            logging.debug(f\"Pesos cargados: forma={lbt_weights.shape}\")\n",
    "            \n",
    "            # Descomprimir el flujo de código\n",
    "            try:\n",
    "                decom_k = self.decompress(decom_k)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error en descompresión: {e}\")\n",
    "            \n",
    "            decom_k = decom_k.astype(np.int16)\n",
    "            # Revertir el desplazamiento\n",
    "            decom_k -= self.offset\n",
    "            \n",
    "            # Deshaceer la cuantización\n",
    "            try:\n",
    "                decom_y = self.dequantize_decom(decom_k)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error en desdecuantización: {e}\")\n",
    "            \n",
    "            # Restaurar bloques desde subbandas\n",
    "            try:\n",
    "                if args.disable_subbands:\n",
    "                    LBT_img = decom_y\n",
    "                else:\n",
    "                    LBT_img = get_blocks(decom_y, self.block_size, self.block_size)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error restaurando bloques desde subbandas: {e}\")\n",
    "            \n",
    "            # Aplicar transformada inversa LBT\n",
    "            try:\n",
    "                H, W, C = LBT_img.shape\n",
    "                decoded_channels = []\n",
    "                \n",
    "                n_blocks_y = H // self.block_size\n",
    "                n_blocks_x = W // self.block_size\n",
    "                \n",
    "                if n_blocks_y <= 0 or n_blocks_x <= 0:\n",
    "                    raise ValueError(f\"Número de bloques inválido: ({n_blocks_y}, {n_blocks_x})\")\n",
    "                \n",
    "                # Procesar cada canal de forma independiente\n",
    "                for c in range(C):\n",
    "                    channel = LBT_img[:, :, c]\n",
    "                    \n",
    "                    # Extraer parches / bloques\n",
    "                    patches = channel.reshape(n_blocks_y, self.block_size, n_blocks_x, self.block_size).swapaxes(1, 2).reshape(-1, self.block_size, self.block_size)\n",
    "                    \n",
    "                    # Configurar LBT con los pesos cargados\n",
    "                    lbt = LBT_Autoencoder(self.block_size)\n",
    "                    lbt.set_weights(lbt_weights[c])\n",
    "                    \n",
    "                    # Aplicar transformada inversa LBT\n",
    "                    rec_patches = lbt.backward(patches)\n",
    "                    \n",
    "                    # Remodelar de vuelta a imagen\n",
    "                    rec_img = rec_patches.reshape(n_blocks_y, n_blocks_x, self.block_size, self.block_size).swapaxes(1, 2).reshape(H, W)\n",
    "                    decoded_channels.append(rec_img)\n",
    "                    \n",
    "                    logging.debug(f\"Canal {c} decodificado\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error en transformada inversa LBT: {e}\")\n",
    "            \n",
    "            # Combinar los canales reconstruidos\n",
    "            CT_y = np.stack(decoded_channels, axis=2)\n",
    "            \n",
    "            # Eliminar el relleno agregado durante la codificación\n",
    "            try:\n",
    "                CT_y = self.remove_padding(CT_y)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error al remover padding: {e}\")\n",
    "            \n",
    "            # Aplicar transformada de color inversa (YCoCg -> RGB)\n",
    "            try:\n",
    "                y = to_RGB(CT_y)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error en transformada de color inversa: {e}\")\n",
    "            \n",
    "            y += self.offset\n",
    "            \n",
    "            # Asegurar que los valores están en el rango [0, 255] y convertir a uint8\n",
    "            y = np.clip(y, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            if np.any(np.isnan(y)):\n",
    "                raise ValueError(\"Imagen decodificada contiene valores NaN\")\n",
    "            \n",
    "            # Escribir la imagen decodificada\n",
    "            try:\n",
    "                output_size = self.decode_write_fn(y, out_fn)\n",
    "            except Exception as e:\n",
    "                raise IOError(f\"Error al escribir imagen decodificada: {out_fn}: {e}\")\n",
    "            \n",
    "            logging.info(f\"Decodificación completada: tamaño salida = {output_size} bytes\")\n",
    "            return output_size\n",
    "            \n",
    "        except (FileNotFoundError, IOError, PermissionError, ValueError) as e:\n",
    "            logging.error(f\"Error en decode_fn: {e}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error inesperado en decode_fn: {e}\")\n",
    "            raise\n",
    "\n",
    "        \n",
    "    def encode(self, in_fn=None, out_fn=None):\n",
    "        \"\"\"\n",
    "        Interfaz pública para codificación.\n",
    "        Utiliza valores por defecto si no se especifican rutas.\n",
    "        \"\"\"\n",
    "        if in_fn is None:\n",
    "            in_fn = self.args.original if hasattr(self.args, 'original') and self.args.original != \"/docs/original.jpg\" else \"../docs/Coco1.jpg\"\n",
    "        if out_fn is None:\n",
    "            out_fn = self.args.encoded if hasattr(self.args, 'encoded') and self.args.encoded != \"/docs/encoded/\" else \"../docs/encoded/lbt_encoded\"\n",
    "        return self.encode_fn(in_fn, out_fn)\n",
    "        \n",
    "    def decode(self, in_fn=None, out_fn=None):\n",
    "        \"\"\"\n",
    "        Interfaz pública para decodificación.\n",
    "        Utiliza valores por defecto si no se especifican rutas.\n",
    "        \"\"\"\n",
    "        if in_fn is None:\n",
    "            in_fn = self.args.encoded if hasattr(self.args, 'encoded') and self.args.encoded != \"/docs/encoded/\" else \"../docs/encoded/lbt_encoded\"\n",
    "        if out_fn is None:\n",
    "            out_fn = self.args.decoded if hasattr(self.args, 'decoded') and self.args.decoded != \"/docs/decoded/\" else \"../docs/decoded/lbt_decoded.jpg\"\n",
    "        return self.decode_fn(in_fn, out_fn)\n",
    "\n",
    "    def quantize_decom(self, decom):\n",
    "        \"\"\"Cuantiza los coeficientes descompuestos.\"\"\"\n",
    "        return self.quantize(decom)\n",
    "\n",
    "    def dequantize_decom(self, decom_k):\n",
    "        \"\"\"Deshace la cuantización de los coeficientes.\"\"\"\n",
    "        return self.dequantize(decom_k)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main.main(parser.parser, logging, CoDec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from visualization import show_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la carpeta /img si no existe\n",
    "import os\n",
    "img_dir = '../img'\n",
    "if not os.path.exists(img_dir):\n",
    "    os.makedirs(img_dir)\n",
    "    print(f\"Carpeta '{img_dir}' creada exitosamente\")\n",
    "else:\n",
    "    print(f\"La carpeta '{img_dir}' ya existe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de rutas\n",
    "src_dir = '../src'\n",
    "docs_dir = '../docs'\n",
    "img_file = 'Pajaro.png'\n",
    "input_img = f'{docs_dir}/Pajaro.png'\n",
    "\n",
    "# Directorios de salida (rutas relativas al directorio src)\n",
    "encoded_dir_rel = f'{docs_dir}/encoded'\n",
    "decoded_dir_rel = f'{docs_dir}/decoded'\n",
    "\n",
    "# Crear directorios si no existen\n",
    "# Nota: Estamos en notebooks/, así que ../docs es la ruta relativa correcta\n",
    "os.makedirs(f'../docs/encoded', exist_ok=True)\n",
    "os.makedirs(f'../docs/decoded', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bloque 16x16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño de bloque 16x16\n",
    "B = 16\n",
    "qs = 16  # Quantization Step Size (controlar la calidad/compresión.)\n",
    "enc_file = f'{encoded_dir_rel}/demo_B{B}'\n",
    "dec_file = f'{decoded_dir_rel}/demo_B{B}.jpg'\n",
    "\n",
    "# Ejecutar codificador y decodificador LBT\n",
    "!cd {src_dir} && python LBT.py encode -o {input_img} -e {enc_file} -B {B} -q {qs}\n",
    "!cd {src_dir} && python LBT.py decode -e {enc_file} -d {dec_file} -B {B} -q {qs}\n",
    "\n",
    "# Mostrar resultados visuales (las rutas son relativas al notebook)\n",
    "show_images(f'../docs/{img_file}', f'../docs/encoded/demo_B{B}.tif', f'../docs/decoded/demo_B{B}.jpg', f'Tamaño de Bloque {B} (QSS={qs})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bloque 8x8 (Estándar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño de bloque 8x8 (estándar en compresión de imágenes, como en JPEG)\n",
    "B = 8\n",
    "enc_file = f'{encoded_dir_rel}/demo_B{B}'\n",
    "dec_file = f'{decoded_dir_rel}/demo_B{B}.jpg'\n",
    "\n",
    "# Ejecutar codificador y decodificador LBT\n",
    "!cd {src_dir} && python LBT.py encode -o {input_img} -e {enc_file} -B {B} -q {qs}\n",
    "!cd {src_dir} && python LBT.py decode -e {enc_file} -d {dec_file} -B {B} -q {qs}\n",
    "\n",
    "# Mostrar y comparar resultados\n",
    "show_images(f'../docs/{img_file}', f'../docs/encoded/demo_B{B}.tif', f'../docs/decoded/demo_B{B}.jpg', f'Tamaño de Bloque {B} (QSS={qs})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bloque 4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño de bloque 4x4 (bloques más pequeños, mayor complejidad computacional)\n",
    "B = 4\n",
    "enc_file = f'{encoded_dir_rel}/demo_B{B}'\n",
    "dec_file = f'{decoded_dir_rel}/demo_B{B}.jpg'\n",
    "\n",
    "# Ejecutar codificador y decodificador LBT\n",
    "!cd {src_dir} && python LBT.py encode -o {input_img} -e {enc_file} -B {B} -q {qs}\n",
    "!cd {src_dir} && python LBT.py decode -e {enc_file} -d {dec_file} -B {B} -q {qs}\n",
    "\n",
    "# Mostrar y comparar resultados\n",
    "show_images(f'../docs/{img_file}', f'../docs/encoded/demo_B{B}.tif', f'../docs/decoded/demo_B{B}.jpg', f'Tamaño de Bloque {B} (QSS={qs})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
