{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# MCTF: Motion Compensated Temporal Filtering\n",
    "\n",
    "## Exercise #3 - Multimedia Systems\n",
    "\n",
    "**Authors:**\n",
    "- Johan Eduardo Cala Torra\n",
    "- Alejandro Gonzales Palma\n",
    "\n",
    "**Institution:** Universidad de AlmerÃ­a (UAL)  \n",
    "**Course:** Multimedia Systems  \n",
    "**Date:** February 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theory-intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Theoretical Explanation\n",
    "\n",
    "### 1.1 What is MCTF?\n",
    "\n",
    "**Motion Compensated Temporal Filtering (MCTF)** is an advanced video coding technique that exploits temporal correlation between consecutive frames using wavelet transforms and motion compensation. Unlike traditional prediction schemes (such as IPP or IBP), MCTF uses a bidirectional temporal filtering scheme implemented through **lifting**.\n",
    "\n",
    "### 1.2 Key Differences from Other Schemes\n",
    "\n",
    "| Feature | IPP (Ex. 1) | IBP (Ex. 2) | **MCTF (Ex. 3)** |\n",
    "|---------|-------------|-------------|------------------|\n",
    "| GOP Structure | I-P-P-P... | I-B-P-B-P... | **I-B-B-B...** |\n",
    "| P-frames | Yes | Yes | **NO** |\n",
    "| B-frames | No | Yes | Yes (all except I) |\n",
    "| Method | Unidirectional prediction | Bidirectional prediction | **Temporal filtering with lifting** |\n",
    "| Structure | Closed-loop | Closed-loop | **Open-loop** |\n",
    "| Scalability | Limited | Moderate | **High** (temporal, spatial, SNR) |\n",
    "\n",
    "**Important:** In MCTF there are **NO P-frames**. Only I-frames (first frame of each GOP) and B-frames (all others)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theory-lifting",
   "metadata": {},
   "source": [
    "### 1.3 The Lifting Scheme\n",
    "\n",
    "The **lifting scheme** is an efficient implementation of the Discrete Wavelet Transform (DWT) consisting of three steps:\n",
    "\n",
    "```\n",
    "+----------+     +----------+     +----------+\n",
    "|  Split   | --> | Predict  | --> |  Update  |\n",
    "+----------+     +----------+     +----------+\n",
    "```\n",
    "\n",
    "**Lifting Equations:**\n",
    "\n",
    "1. **Split:** Separate into even and odd samples\n",
    "   - Even: `e_i = x_{2i}`\n",
    "   - Odd: `o_i = x_{2i+1}`\n",
    "\n",
    "2. **Predict:** Generate high-frequency component (residual)\n",
    "   - `H_i = o_i - P(e_i)`\n",
    "   - Where `P(e_i)` is the prediction based on even samples\n",
    "\n",
    "3. **Update:** Refine low-frequency component\n",
    "   - `L_i = e_i + U(H_i)`\n",
    "   - Where `U(H_i)` is the update based on residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theory-mctf",
   "metadata": {},
   "source": [
    "### 1.4 MCTF Temporal Decomposition\n",
    "\n",
    "MCTF extends the lifting scheme to the temporal domain with motion compensation:\n",
    "\n",
    "**MCTF Equations:**\n",
    "\n",
    "1. **Motion Estimation:** Find motion vectors that minimize error\n",
    "   - `MV = argmin ||I_t(x,y) - I_{t+1}(x+dx, y+dy)||^2`\n",
    "\n",
    "2. **Predict Step:** Generate residual using bidirectional MC\n",
    "   - `H_t = I_odd - (MC(I_prev, MV_bwd) + MC(I_next, MV_fwd))/2 * alpha`\n",
    "\n",
    "3. **Update Step:** Refine low-pass with residual information\n",
    "   - `L_t = I_even + MC(H_t, MV_fwd) * beta`\n",
    "\n",
    "Where `alpha` (predict) and `beta` (update) are wavelet-dependent coefficients.\n",
    "\n",
    "### 1.5 Supported Wavelet Types\n",
    "\n",
    "| Wavelet | Predict (alpha) | Update (beta) | Characteristics |\n",
    "|---------|-----------------|---------------|------------------|\n",
    "| **Haar** | 1.0 | 0.5 | Simplest, less efficient |\n",
    "| **5/3 (LeGall)** | 0.5 | 0.25 | Good balance, reversible |\n",
    "| **9/7 (CDF)** | 1.586 | 0.053 | Best compression, irreversible |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theory-gop",
   "metadata": {},
   "source": [
    "### 1.6 GOP Structure in MCTF\n",
    "\n",
    "```\n",
    "GOP with 8 frames:\n",
    "\n",
    "Original:    F0   F1   F2   F3   F4   F5   F6   F7\n",
    "Type:        I    B    B    B    B    B    B    B\n",
    "Level 1:     L0---H0---L1---H1---L2---H2---L3---H3\n",
    "Level 2:     L0--------H0--------L1--------H1\n",
    "Level 3:     L0------------------H0\n",
    "```\n",
    "\n",
    "- **L frames (Low-pass):** Contain low temporal frequency information\n",
    "- **H frames (High-pass):** Contain high temporal frequency information (residuals)\n",
    "\n",
    "### 1.7 References\n",
    "\n",
    "1. **Gonzalez-Ruiz, V.** \"Motion Compensated Temporal Filtering (MCTF)\" - https://github.com/vicente-gonzalez-ruiz/motion_compensated_temporal_filtering\n",
    "2. **Ohm, J.R.** (1994). \"Three-dimensional subband coding with motion compensation\" - IEEE Transactions on Image Processing\n",
    "3. **Pesquet-Popescu, B., Bottreau, V.** (2001). \"Three-dimensional lifting schemes for motion compensated video compression\"\n",
    "4. **Secker, A., Taubman, D.** (2003). \"Lifting-based invertible motion adaptive transform (LIMAT) framework\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impl-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Implementation\n",
    "\n",
    "The MCTF implementation consists of 4 modules:\n",
    "1. `motion_estimation.py` - Bidirectional motion estimation\n",
    "2. `motion_compensation.py` - Motion compensation\n",
    "3. `temporal_filtering.py` - Lifting-based temporal filtering\n",
    "4. `MCTF.py` - Main codec class\n",
    "\n",
    "Execute the following cells to generate the implementation files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31abb05-7547-46b9-92f9-40af500bf6bc",
   "metadata": {},
   "source": [
    "### 2.0 Platform Utilities Module\n",
    "\n",
    "This module provides cross-platform compatibility for file paths and temporary directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858054f9-0afe-4c3b-a6ec-5fe1a1b7ea47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/platform_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/platform_utils.py\n",
    "\"\"\"\n",
    "Cross-platform compatibility module for VCF.\n",
    "\n",
    "This module provides functions and constants to handle file paths\n",
    "compatible with Windows, Linux, and macOS.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def get_temp_dir():\n",
    "    \"\"\"Get the system temporary directory in a cross-platform way.\"\"\"\n",
    "    return tempfile.gettempdir()\n",
    "\n",
    "\n",
    "def get_vcf_temp_dir():\n",
    "    \"\"\"Get the VCF temporary directory, creating it if it doesn't exist.\"\"\"\n",
    "    if sys.platform == 'win32':\n",
    "        temp_dir = \"C:/tmp\"\n",
    "    else:\n",
    "        temp_dir = \"/tmp\"\n",
    "    \n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    return temp_dir\n",
    "\n",
    "\n",
    "def get_temp_path(filename):\n",
    "    \"\"\"Build a full path to a file in the VCF temporary directory.\"\"\"\n",
    "    return os.path.join(get_vcf_temp_dir(), filename)\n",
    "\n",
    "\n",
    "def ensure_description_file(description_text):\n",
    "    \"\"\"Create the description.txt file required by parser.py.\"\"\"\n",
    "    desc_path = get_temp_path(\"description.txt\")\n",
    "    with open(desc_path, 'w') as f:\n",
    "        f.write(description_text)\n",
    "\n",
    "\n",
    "def get_file_uri(path):\n",
    "    \"\"\"Convert a file path to file:// URI format.\"\"\"\n",
    "    path = os.path.abspath(path)\n",
    "    if sys.platform == 'win32':\n",
    "        path = path.replace('\\\\', '/')\n",
    "        return f\"file:///{path}\"\n",
    "    else:\n",
    "        return f\"file://{path}\"\n",
    "\n",
    "\n",
    "# Predefined path constants\n",
    "ENCODE_INPUT = \"http://www.hpca.ual.es/~vruiz/videos/mobile_352x288x30x420x300.mp4\"\n",
    "ENCODE_OUTPUT_PREFIX = get_temp_path(\"encoded\")\n",
    "DECODE_INPUT_PREFIX = ENCODE_OUTPUT_PREFIX\n",
    "DECODE_OUTPUT_PREFIX = get_temp_path(\"decoded\")\n",
    "DECODE_OUTPUT = get_temp_path(\"decoded.mp4\")\n",
    "\n",
    "ORIGINAL = get_temp_path(\"original.png\")\n",
    "ENCODED = get_temp_path(\"encoded\")\n",
    "DECODED = get_temp_path(\"decoded.png\")\n",
    "\n",
    "FRAME_PREFIX = get_temp_path(\"img_\")\n",
    "ORIGINAL_FRAME_PREFIX = get_temp_path(\"original_\")\n",
    "DECODED_FRAME_PREFIX = get_temp_path(\"decoded_\")\n",
    "\n",
    "\n",
    "def get_original_frame_path(index, digits=4):\n",
    "    \"\"\"Generate path for an original frame.\"\"\"\n",
    "    return f\"{ORIGINAL_FRAME_PREFIX}{index:0{digits}d}.png\"\n",
    "\n",
    "\n",
    "def get_decoded_frame_path(index, digits=4):\n",
    "    \"\"\"Generate path for a decoded frame.\"\"\"\n",
    "    return f\"{DECODED_FRAME_PREFIX}{index:0{digits}d}.png\"\n",
    "\n",
    "\n",
    "# Ensure temp directory exists on import\n",
    "_temp_dir = get_vcf_temp_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impl-me-title",
   "metadata": {},
   "source": [
    "### 2.1 Motion Estimation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impl-motion-estimation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/motion_estimation.py\n",
    "\"\"\"\n",
    "Bidirectional motion estimation using block matching.\n",
    "\n",
    "This module implements bidirectional motion estimation for\n",
    "MCTF (Motion Compensated Temporal Filtering).\n",
    "\n",
    "References:\n",
    "    - Ohm, J.R. (1994). \"Three-dimensional subband coding with motion compensation\"\n",
    "      IEEE Transactions on Image Processing, 9:559-571\n",
    "    - Gonzalez-Ruiz, V. \"MCTF\"\n",
    "      https://github.com/vicente-gonzalez-ruiz/motion_compensated_temporal_filtering\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import logging\n",
    "\n",
    "\n",
    "def block_matching_bidirectional(\n",
    "    frame_current: np.ndarray,\n",
    "    frame_prev: np.ndarray,\n",
    "    frame_next: np.ndarray,\n",
    "    block_size: int = 16,\n",
    "    search_range: int = 16\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Bidirectional motion estimation using block matching.\n",
    "    \n",
    "    Implements Full Search Block Matching with SAD (Sum of Absolute Differences)\n",
    "    metric to find best forward and backward motion vectors.\n",
    "    \n",
    "    Args:\n",
    "        frame_current: Current frame (being predicted)\n",
    "        frame_prev: Previous frame (backward reference)\n",
    "        frame_next: Next frame (forward reference)\n",
    "        block_size: Block size NxN (default: 16)\n",
    "        search_range: Search range +/- pixels (default: 16)\n",
    "        \n",
    "    Returns:\n",
    "        mv_forward: Forward motion vectors (current->next) [blocks_h, blocks_w, 2]\n",
    "        mv_backward: Backward motion vectors (current->prev) [blocks_h, blocks_w, 2]\n",
    "    \"\"\"\n",
    "    \n",
    "    height, width = frame_current.shape[:2]\n",
    "    \n",
    "    # Number of blocks in each dimension\n",
    "    blocks_h = height // block_size\n",
    "    blocks_w = width // block_size\n",
    "    \n",
    "    # Initialize motion vector fields\n",
    "    mv_forward = np.zeros((blocks_h, blocks_w, 2), dtype=np.float32)\n",
    "    mv_backward = np.zeros((blocks_h, blocks_w, 2), dtype=np.float32)\n",
    "    \n",
    "    logging.debug(f\"Block matching: {blocks_h}x{blocks_w} blocks, size={block_size}, range={search_range}\")\n",
    "    \n",
    "    # Iterate over each block\n",
    "    for by in range(blocks_h):\n",
    "        for bx in range(blocks_w):\n",
    "            # Current block coordinates\n",
    "            y_start = by * block_size\n",
    "            x_start = bx * block_size\n",
    "            y_end = y_start + block_size\n",
    "            x_end = x_start + block_size\n",
    "            \n",
    "            # Extract current block\n",
    "            current_block = frame_current[y_start:y_end, x_start:x_end]\n",
    "            \n",
    "            # === Forward search (current -> next) ===\n",
    "            mv_forward[by, bx] = _search_best_match(\n",
    "                current_block, frame_next, \n",
    "                y_start, x_start, block_size,\n",
    "                height, width, search_range\n",
    "            )\n",
    "            \n",
    "            # === Backward search (current -> prev) ===\n",
    "            mv_backward[by, bx] = _search_best_match(\n",
    "                current_block, frame_prev,\n",
    "                y_start, x_start, block_size,\n",
    "                height, width, search_range\n",
    "            )\n",
    "    \n",
    "    return mv_forward, mv_backward\n",
    "\n",
    "\n",
    "def _search_best_match(\n",
    "    current_block: np.ndarray,\n",
    "    reference_frame: np.ndarray,\n",
    "    y_start: int,\n",
    "    x_start: int,\n",
    "    block_size: int,\n",
    "    height: int,\n",
    "    width: int,\n",
    "    search_range: int\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Search for best match of a block in reference frame.\n",
    "    \n",
    "    Args:\n",
    "        current_block: Block to search\n",
    "        reference_frame: Frame to search in\n",
    "        y_start, x_start: Block position in original frame\n",
    "        block_size: Block size\n",
    "        height, width: Frame dimensions\n",
    "        search_range: Search range\n",
    "        \n",
    "    Returns:\n",
    "        (dx, dy): Motion vector that minimizes SAD\n",
    "    \"\"\"\n",
    "    \n",
    "    min_sad = float('inf')\n",
    "    best_mv = (0, 0)\n",
    "    \n",
    "    for dy in range(-search_range, search_range + 1):\n",
    "        for dx in range(-search_range, search_range + 1):\n",
    "            # Coordinates in reference frame\n",
    "            ref_y = y_start + dy\n",
    "            ref_x = x_start + dx\n",
    "            \n",
    "            # Check boundaries\n",
    "            if (ref_y >= 0 and ref_y + block_size <= height and\n",
    "                ref_x >= 0 and ref_x + block_size <= width):\n",
    "                \n",
    "                # Extract reference block\n",
    "                ref_block = reference_frame[\n",
    "                    ref_y:ref_y + block_size,\n",
    "                    ref_x:ref_x + block_size\n",
    "                ]\n",
    "                \n",
    "                # Calculate SAD (Sum of Absolute Differences) - vectorized\n",
    "                sad = np.sum(np.abs(\n",
    "                    current_block.astype(np.float32) - \n",
    "                    ref_block.astype(np.float32)\n",
    "                ))\n",
    "                \n",
    "                # Update best match\n",
    "                if sad < min_sad:\n",
    "                    min_sad = sad\n",
    "                    best_mv = (dx, dy)\n",
    "    \n",
    "    return best_mv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impl-mc-title",
   "metadata": {},
   "source": [
    "### 2.2 Motion Compensation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impl-motion-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/motion_compensation.py\n",
    "\"\"\"\n",
    "Motion compensation for MCTF.\n",
    "\n",
    "This module implements motion compensation that applies motion vectors\n",
    "to reference frames to generate predictions.\n",
    "\n",
    "References:\n",
    "    - Gonzalez-Ruiz, V. \"Motion Compensation\"\n",
    "      https://github.com/vicente-gonzalez-ruiz/motion_compensation\n",
    "    - Pesquet-Popescu, B., Bottreau, V. (2001). \"Three-dimensional lifting \n",
    "      schemes for motion compensated video compression\"\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "\n",
    "def motion_compensate(\n",
    "    frame: np.ndarray,\n",
    "    motion_vectors: np.ndarray,\n",
    "    block_size: int = 16\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply motion compensation to a frame.\n",
    "    \n",
    "    Generates a compensated frame by shifting blocks according to\n",
    "    the provided motion vectors.\n",
    "    \n",
    "    Args:\n",
    "        frame: Reference frame\n",
    "        motion_vectors: Motion vector field [blocks_h, blocks_w, 2]\n",
    "        block_size: Block size (default: 16)\n",
    "        \n",
    "    Returns:\n",
    "        compensated_frame: Motion compensated frame\n",
    "    \"\"\"\n",
    "    \n",
    "    height, width = frame.shape[:2]\n",
    "    compensated_frame = np.zeros_like(frame, dtype=np.float32)\n",
    "    \n",
    "    blocks_h, blocks_w = motion_vectors.shape[:2]\n",
    "    \n",
    "    logging.debug(f\"Motion compensate: {blocks_h}x{blocks_w} blocks, size={block_size}\")\n",
    "    \n",
    "    for by in range(blocks_h):\n",
    "        for bx in range(blocks_w):\n",
    "            # Destination block coordinates\n",
    "            y_start = by * block_size\n",
    "            x_start = bx * block_size\n",
    "            y_end = min(y_start + block_size, height)\n",
    "            x_end = min(x_start + block_size, width)\n",
    "            \n",
    "            # Motion vector\n",
    "            dx, dy = motion_vectors[by, bx]\n",
    "            \n",
    "            # Coordinates in reference frame\n",
    "            ref_y = int(y_start + dy)\n",
    "            ref_x = int(x_start + dx)\n",
    "            \n",
    "            # Check boundaries\n",
    "            if (ref_y >= 0 and ref_y + block_size <= height and\n",
    "                ref_x >= 0 and ref_x + block_size <= width):\n",
    "                \n",
    "                # Copy compensated block\n",
    "                compensated_frame[y_start:y_end, x_start:x_end] = \\\n",
    "                    frame[ref_y:ref_y + (y_end - y_start), \n",
    "                          ref_x:ref_x + (x_end - x_start)]\n",
    "            else:\n",
    "                # If out of bounds, copy original block\n",
    "                compensated_frame[y_start:y_end, x_start:x_end] = \\\n",
    "                    frame[y_start:y_end, x_start:x_end]\n",
    "    \n",
    "    return compensated_frame\n",
    "\n",
    "\n",
    "def motion_compensate_bidirectional(\n",
    "    frame_prev: np.ndarray,\n",
    "    frame_next: np.ndarray,\n",
    "    mv_backward: np.ndarray,\n",
    "    mv_forward: np.ndarray,\n",
    "    block_size: int = 16\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Bidirectional motion compensation for B-frames.\n",
    "    \n",
    "    Generates a bidirectional prediction by averaging compensations\n",
    "    from previous and next frames.\n",
    "    \n",
    "    Args:\n",
    "        frame_prev: Previous frame (backward reference)\n",
    "        frame_next: Next frame (forward reference)\n",
    "        mv_backward: Backward motion vectors\n",
    "        mv_forward: Forward motion vectors\n",
    "        block_size: Block size (default: 16)\n",
    "        \n",
    "    Returns:\n",
    "        prediction: Bidirectional prediction frame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compensate from previous frame\n",
    "    mc_prev = motion_compensate(frame_prev, mv_backward, block_size)\n",
    "    \n",
    "    # Compensate from next frame\n",
    "    mc_next = motion_compensate(frame_next, mv_forward, block_size)\n",
    "    \n",
    "    # Bidirectional prediction (average)\n",
    "    prediction = (mc_prev + mc_next) / 2.0\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impl-tf-title",
   "metadata": {},
   "source": [
    "### 2.3 Temporal Filtering Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impl-temporal-filtering",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/temporal_filtering.py\n",
    "\"\"\"\n",
    "Temporal filtering using lifting scheme with motion compensation.\n",
    "\n",
    "This module implements temporal wavelet filtering for MCTF using\n",
    "the lifting scheme with Predict and Update steps.\n",
    "\n",
    "References:\n",
    "    - Pesquet-Popescu, B., Bottreau, V. (2001). \"Three-dimensional lifting \n",
    "      schemes for motion compensated video compression\"\n",
    "    - Secker, A., Taubman, D. (2003). \"Lifting-based invertible motion \n",
    "      adaptive transform (LIMAT) framework\"\n",
    "    - Gonzalez-Ruiz, V. \"MCTF\"\n",
    "      https://github.com/vicente-gonzalez-ruiz/motion_compensated_temporal_filtering\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "import logging\n",
    "\n",
    "from motion_compensation import motion_compensate\n",
    "\n",
    "\n",
    "# Wavelet coefficients for lifting scheme\n",
    "WAVELET_COEFFICIENTS = {\n",
    "    'haar': {\n",
    "        'predict': 1.0,\n",
    "        'update': 0.5\n",
    "    },\n",
    "    '5/3': {\n",
    "        'predict': 0.5,\n",
    "        'update': 0.25\n",
    "    },\n",
    "    '9/7': {\n",
    "        'predict': 1.586134342,\n",
    "        'update': 0.052980118\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def get_wavelet_coefficients(wavelet_type: str) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Get predict and update coefficients for a wavelet.\n",
    "    \n",
    "    Args:\n",
    "        wavelet_type: Wavelet type ('haar', '5/3', '9/7')\n",
    "        \n",
    "    Returns:\n",
    "        (predict_coef, update_coef): Lifting scheme coefficients\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If wavelet type is not supported\n",
    "    \"\"\"\n",
    "    if wavelet_type not in WAVELET_COEFFICIENTS:\n",
    "        raise ValueError(\n",
    "            f\"Wavelet type '{wavelet_type}' not supported. \"\n",
    "            f\"Supported types: {list(WAVELET_COEFFICIENTS.keys())}\"\n",
    "        )\n",
    "    \n",
    "    coeffs = WAVELET_COEFFICIENTS[wavelet_type]\n",
    "    return coeffs['predict'], coeffs['update']\n",
    "\n",
    "\n",
    "def temporal_filter_lifting(\n",
    "    frames: List[np.ndarray],\n",
    "    motion_vectors_forward: List[np.ndarray],\n",
    "    motion_vectors_backward: List[np.ndarray],\n",
    "    wavelet_type: str = '5/3',\n",
    "    block_size: int = 16\n",
    ") -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Apply temporal filtering using lifting scheme with motion compensation.\n",
    "    \n",
    "    Implements IBB... scheme where even frames are low-pass (L)\n",
    "    and odd frames generate high-pass (H) as prediction residuals.\n",
    "    \n",
    "    Args:\n",
    "        frames: List of frames to filter\n",
    "        motion_vectors_forward: List of forward MVs\n",
    "        motion_vectors_backward: List of backward MVs\n",
    "        wavelet_type: Wavelet type ('haar', '5/3', '9/7')\n",
    "        block_size: Block size for MC\n",
    "        \n",
    "    Returns:\n",
    "        low_pass: Low temporal frequency frames (L)\n",
    "        high_pass: High temporal frequency frames (H/residuals)\n",
    "    \"\"\"\n",
    "    \n",
    "    n_frames = len(frames)\n",
    "    predict_coef, update_coef = get_wavelet_coefficients(wavelet_type)\n",
    "    \n",
    "    logging.info(f\"Temporal filtering {n_frames} frames with {wavelet_type} wavelet\")\n",
    "    \n",
    "    low_pass = []\n",
    "    high_pass = []\n",
    "    \n",
    "    # Process frame pairs (even, odd)\n",
    "    for i in range(0, n_frames - 1, 2):\n",
    "        frame_even = frames[i].astype(np.float32)      # Even frame (t=0,2,4...)\n",
    "        frame_odd = frames[i + 1].astype(np.float32)   # Odd frame (t=1,3,5...)\n",
    "        \n",
    "        # === PREDICT STEP ===\n",
    "        # Predict odd frame using MC from neighboring even frames\n",
    "        \n",
    "        # MC from previous frame (current even)\n",
    "        mc_prev = motion_compensate(\n",
    "            frame_even,\n",
    "            motion_vectors_backward[i] if i < len(motion_vectors_backward) else np.zeros_like(motion_vectors_backward[0]),\n",
    "            block_size\n",
    "        )\n",
    "        \n",
    "        # MC from next frame (even i+2) if exists\n",
    "        if i + 2 < n_frames:\n",
    "            mc_next = motion_compensate(\n",
    "                frames[i + 2].astype(np.float32),\n",
    "                motion_vectors_forward[i + 1] if i + 1 < len(motion_vectors_forward) else np.zeros_like(motion_vectors_forward[0]),\n",
    "                block_size\n",
    "            )\n",
    "        else:\n",
    "            mc_next = mc_prev\n",
    "        \n",
    "        # Bidirectional prediction\n",
    "        prediction = (mc_prev + mc_next) * predict_coef / 2.0\n",
    "        \n",
    "        # High frequency residual (H)\n",
    "        h_frame = frame_odd - prediction\n",
    "        high_pass.append(h_frame)\n",
    "        \n",
    "        # === UPDATE STEP ===\n",
    "        # Update even frame with residual information\n",
    "        mc_residual = motion_compensate(\n",
    "            h_frame,\n",
    "            motion_vectors_forward[i] if i < len(motion_vectors_forward) else np.zeros_like(motion_vectors_forward[0]),\n",
    "            block_size\n",
    "        )\n",
    "        \n",
    "        # Update (L)\n",
    "        l_frame = frame_even + mc_residual * update_coef\n",
    "        low_pass.append(l_frame)\n",
    "    \n",
    "    # If odd number of frames, last one passes as low-pass\n",
    "    if n_frames % 2 != 0:\n",
    "        low_pass.append(frames[-1].astype(np.float32))\n",
    "    \n",
    "    logging.info(f\"Temporal filtering complete: {len(low_pass)} L frames, {len(high_pass)} H frames\")\n",
    "\n",
    "    return low_pass, high_pass\n",
    "\n",
    "\n",
    "def inverse_temporal_filter_lifting(\n",
    "    low_pass: List[np.ndarray],\n",
    "    high_pass: List[np.ndarray],\n",
    "    motion_vectors_forward: List[np.ndarray],\n",
    "    motion_vectors_backward: List[np.ndarray],\n",
    "    wavelet_type: str = '5/3',\n",
    "    block_size: int = 16\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Reconstruct frames from temporal decomposition.\n",
    "\n",
    "    Applies inverse lifting scheme to recover original frames\n",
    "    from L (low-pass) and H (high-pass) components.\n",
    "\n",
    "    Args:\n",
    "        low_pass: L frames (low temporal frequency)\n",
    "        high_pass: H frames (high temporal frequency)\n",
    "        motion_vectors_forward: Forward MVs\n",
    "        motion_vectors_backward: Backward MVs\n",
    "        wavelet_type: Wavelet type used in encoding\n",
    "        block_size: Block size for MC\n",
    "\n",
    "    Returns:\n",
    "        reconstructed_frames: List of reconstructed frames\n",
    "    \"\"\"\n",
    "\n",
    "    predict_coef, update_coef = get_wavelet_coefficients(wavelet_type)\n",
    "\n",
    "    n_low = len(low_pass)\n",
    "    n_high = len(high_pass)\n",
    "\n",
    "    logging.info(f\"Inverse temporal filtering: {n_low} L frames, {n_high} H frames\")\n",
    "\n",
    "    reconstructed_frames = []\n",
    "\n",
    "    for i in range(n_high):\n",
    "        l_frame = low_pass[i].astype(np.float32)\n",
    "        h_frame = high_pass[i].astype(np.float32)\n",
    "\n",
    "        # === INVERSE UPDATE ===\n",
    "        # Recover original even frame\n",
    "        mc_residual = motion_compensate(\n",
    "            h_frame,\n",
    "            motion_vectors_forward[2 * i] if 2 * i < len(motion_vectors_forward) else np.zeros_like(motion_vectors_forward[0]),\n",
    "            block_size\n",
    "        )\n",
    "\n",
    "        frame_even = l_frame - mc_residual * update_coef\n",
    "        reconstructed_frames.append(frame_even)\n",
    "\n",
    "        # === INVERSE PREDICT ===\n",
    "        # Recover original odd frame\n",
    "\n",
    "        # MC for prediction\n",
    "        mc_prev = motion_compensate(\n",
    "            frame_even,\n",
    "            motion_vectors_backward[2 * i] if 2 * i < len(motion_vectors_backward) else np.zeros_like(motion_vectors_backward[0]),\n",
    "            block_size\n",
    "        )\n",
    "\n",
    "        if i + 1 < n_low:\n",
    "            mc_next = motion_compensate(\n",
    "                low_pass[i + 1].astype(np.float32),\n",
    "                motion_vectors_forward[2 * i + 1] if 2 * i + 1 < len(motion_vectors_forward) else np.zeros_like(motion_vectors_forward[0]),\n",
    "                block_size\n",
    "            )\n",
    "        else:\n",
    "            mc_next = mc_prev\n",
    "\n",
    "        # Bidirectional prediction\n",
    "        prediction = (mc_prev + mc_next) * predict_coef / 2.0\n",
    "\n",
    "        # Inverse predict\n",
    "        frame_odd = h_frame + prediction\n",
    "        reconstructed_frames.append(frame_odd)\n",
    "\n",
    "    # If there was an extra frame in low_pass (odd number of frames)\n",
    "    if n_low > n_high:\n",
    "        reconstructed_frames.append(low_pass[-1].astype(np.float32))\n",
    "\n",
    "    logging.info(f\"Inverse temporal filtering complete: {len(reconstructed_frames)} frames\")\n",
    "\n",
    "    return reconstructed_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impl-mctf-title",
   "metadata": {},
   "source": [
    "### 2.4 Main MCTF Codec Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impl-mctf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/MCTF.py\n",
    "\"\"\"\n",
    "MCTF: Motion Compensated Temporal Filtering codec.\n",
    "\n",
    "This module implements a video codec based on temporal filtering\n",
    "with motion compensation using lifting scheme.\n",
    "\n",
    "GOP structure: IBB... (I-frame followed by B-frames, NO P-frames)\n",
    "- I-frame: coded independently (intra)\n",
    "- B-frames: bidirectionally predicted\n",
    "\n",
    "References:\n",
    "    - Ohm, J.R. (1994). \"Three-dimensional subband coding with motion compensation\"\n",
    "    - Pesquet-Popescu, B., Bottreau, V. (2001). \"Three-dimensional lifting schemes\"\n",
    "    - Gonzalez-Ruiz, V. \"MCTF\" https://github.com/vicente-gonzalez-ruiz/motion_compensated_temporal_filtering\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import cv2\n",
    "import av\n",
    "from PIL import Image\n",
    "import importlib\n",
    "import pickle\n",
    "import tempfile\n",
    "\n",
    "import main\n",
    "import platform_utils as pu\n",
    "\n",
    "# Cross-platform initialization\n",
    "TMP_DIR = pu.get_vcf_temp_dir()\n",
    "pu.ensure_description_file(__doc__)\n",
    "\n",
    "import parser\n",
    "import entropy_video_coding as EVC\n",
    "\n",
    "from motion_estimation import block_matching_bidirectional\n",
    "from motion_compensation import motion_compensate\n",
    "from temporal_filtering import temporal_filter_lifting, inverse_temporal_filter_lifting\n",
    "\n",
    "# Default parameters\n",
    "DEFAULT_GOP_SIZE = 16\n",
    "DEFAULT_TEMPORAL_LEVELS = 4\n",
    "DEFAULT_BLOCK_SIZE = 16\n",
    "DEFAULT_SEARCH_RANGE = 16\n",
    "DEFAULT_WAVELET_TYPE = '5/3'\n",
    "\n",
    "# Encoder parser\n",
    "parser.parser_encode.add_argument(\"-V\", \"--video_input\", type=parser.int_or_str,\n",
    "    help=f\"Input video (default: {EVC.ENCODE_INPUT})\",\n",
    "    default=EVC.ENCODE_INPUT)\n",
    "parser.parser_encode.add_argument(\"-O\", \"--video_output\", type=parser.int_or_str,\n",
    "    help=f\"Output prefix (default: {EVC.ENCODE_OUTPUT_PREFIX})\",\n",
    "    default=EVC.ENCODE_OUTPUT_PREFIX)\n",
    "parser.parser_encode.add_argument(\"-T\", \"--transform\", type=str,\n",
    "    help=f\"2D-transform (default: {EVC.DEFAULT_TRANSFORM})\",\n",
    "    default=EVC.DEFAULT_TRANSFORM)\n",
    "parser.parser_encode.add_argument(\"-N\", \"--number_of_frames\", type=parser.int_or_str,\n",
    "    help=f\"Number of frames to encode (default: {EVC.N_FRAMES})\",\n",
    "    default=f\"{EVC.N_FRAMES}\")\n",
    "parser.parser_encode.add_argument(\"--gop_size\", type=int,\n",
    "    help=f\"GOP size (default: {DEFAULT_GOP_SIZE})\",\n",
    "    default=DEFAULT_GOP_SIZE)\n",
    "parser.parser_encode.add_argument(\"--temporal_levels\", type=int,\n",
    "    help=f\"Temporal decomposition levels (default: {DEFAULT_TEMPORAL_LEVELS})\",\n",
    "    default=DEFAULT_TEMPORAL_LEVELS)\n",
    "parser.parser_encode.add_argument(\"--block_size\", type=int,\n",
    "    help=f\"Block size for motion estimation (default: {DEFAULT_BLOCK_SIZE})\",\n",
    "    default=DEFAULT_BLOCK_SIZE)\n",
    "parser.parser_encode.add_argument(\"--search_range\", type=int,\n",
    "    help=f\"Search range for motion estimation (default: {DEFAULT_SEARCH_RANGE})\",\n",
    "    default=DEFAULT_SEARCH_RANGE)\n",
    "parser.parser_encode.add_argument(\"--wavelet_type\", type=str,\n",
    "    help=f\"Temporal wavelet type: haar, 5/3, 9/7 (default: {DEFAULT_WAVELET_TYPE})\",\n",
    "    default=DEFAULT_WAVELET_TYPE)\n",
    "\n",
    "# Decoder parser\n",
    "parser.parser_decode.add_argument(\"-V\", \"--video_input\", type=parser.int_or_str,\n",
    "    help=f\"Input MCTF stream prefix (default: {EVC.ENCODE_OUTPUT_PREFIX})\",\n",
    "    default=EVC.ENCODE_OUTPUT_PREFIX)\n",
    "parser.parser_decode.add_argument(\"-O\", \"--video_output\", type=parser.int_or_str,\n",
    "    help=f\"Output prefix (default: {EVC.DECODE_OUTPUT_PREFIX})\",\n",
    "    default=EVC.DECODE_OUTPUT_PREFIX)\n",
    "parser.parser_decode.add_argument(\"-T\", \"--transform\", type=str,\n",
    "    help=f\"2D-transform (default: {EVC.DEFAULT_TRANSFORM})\",\n",
    "    default=EVC.DEFAULT_TRANSFORM)\n",
    "parser.parser_decode.add_argument(\"-N\", \"--number_of_frames\", type=parser.int_or_str,\n",
    "    help=f\"Number of frames to decode (default: {EVC.N_FRAMES})\",\n",
    "    default=f\"{EVC.N_FRAMES}\")\n",
    "parser.parser_decode.add_argument(\"--gop_size\", type=int,\n",
    "    help=f\"GOP size (default: {DEFAULT_GOP_SIZE})\",\n",
    "    default=DEFAULT_GOP_SIZE)\n",
    "parser.parser_decode.add_argument(\"--temporal_levels\", type=int,\n",
    "    help=f\"Temporal decomposition levels (default: {DEFAULT_TEMPORAL_LEVELS})\",\n",
    "    default=DEFAULT_TEMPORAL_LEVELS)\n",
    "parser.parser_decode.add_argument(\"--block_size\", type=int,\n",
    "    help=f\"Block size for motion estimation (default: {DEFAULT_BLOCK_SIZE})\",\n",
    "    default=DEFAULT_BLOCK_SIZE)\n",
    "parser.parser_decode.add_argument(\"--search_range\", type=int,\n",
    "    help=f\"Search range for motion estimation (default: {DEFAULT_SEARCH_RANGE})\",\n",
    "    default=DEFAULT_SEARCH_RANGE)\n",
    "parser.parser_decode.add_argument(\"--wavelet_type\", type=str,\n",
    "    help=f\"Temporal wavelet type: haar, 5/3, 9/7 (default: {DEFAULT_WAVELET_TYPE})\",\n",
    "    default=DEFAULT_WAVELET_TYPE)\n",
    "\n",
    "args = parser.parser.parse_known_args()[0]\n",
    "\n",
    "# Import spatial transform\n",
    "if __debug__:\n",
    "    if args.debug:\n",
    "        print(f\"MCTF: Importing {args.transform}\")\n",
    "\n",
    "try:\n",
    "    transform = importlib.import_module(args.transform)\n",
    "except ImportError as e:\n",
    "    print(f\"Error: Could not find {args.transform} module ({e})\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "class CoDec(EVC.CoDec):\n",
    "    \"\"\"\n",
    "    MCTF (Motion Compensated Temporal Filtering) Codec.\n",
    "    \n",
    "    Implements video compression using:\n",
    "    1. Bidirectional motion estimation\n",
    "    2. Temporal filtering with lifting scheme (Predict + Update)\n",
    "    3. 2D spatial transform (DCT or DWT)\n",
    "    4. Quantization and entropy coding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        logging.debug(\"trace\")\n",
    "        super().__init__(args)\n",
    "        \n",
    "        # MCTF configuration\n",
    "        self.gop_size = args.gop_size\n",
    "        self.temporal_levels = args.temporal_levels\n",
    "        self.block_size = args.block_size\n",
    "        self.search_range = args.search_range\n",
    "        self.wavelet_type = args.wavelet_type\n",
    "        \n",
    "        # Spatial transform codec\n",
    "        self.transform_codec = transform.CoDec(args)\n",
    "        \n",
    "        logging.info(f\"MCTF Codec initialized:\")\n",
    "        logging.info(f\"  GOP size: {self.gop_size}\")\n",
    "        logging.info(f\"  Temporal levels: {self.temporal_levels}\")\n",
    "        logging.info(f\"  Block size: {self.block_size}\")\n",
    "        logging.info(f\"  Search range: {self.search_range}\")\n",
    "        logging.info(f\"  Wavelet type: {self.wavelet_type}\")\n",
    "        logging.info(f\"  Spatial transform: {args.transform}\")\n",
    "\n",
    "    def bye(self):\n",
    "        \"\"\"Override bye() to use video_input/video_output.\"\"\"\n",
    "        logging.debug(\"trace\")\n",
    "        if __debug__:\n",
    "            if self.encoding:\n",
    "                BPP = (self.total_output_size*8)/(self.N_frames*self.width*self.height)\n",
    "                logging.info(f\"Output bit-rate = {BPP} bits/pixel\")\n",
    "                # Save metadata\n",
    "                with open(f\"{self.args.video_output}.txt\", 'w') as f:\n",
    "                    f.write(f\"{self.args.video_input}\\n\")\n",
    "                    f.write(f\"{self.N_frames}\\n\")\n",
    "                    f.write(f\"{self.height}\\n\")\n",
    "                    f.write(f\"{self.width}\\n\")\n",
    "                    f.write(f\"{BPP}\\n\")\n",
    "            else:\n",
    "                # Read metadata and calculate distortion\n",
    "                with open(f\"{self.args.video_input}.txt\", 'r') as f:\n",
    "                    original_file = f.readline().strip()\n",
    "                    logging.info(f\"original_file = {original_file}\")\n",
    "                    N_frames = int(f.readline().strip())\n",
    "                    logging.info(f\"N_frames = {N_frames}\")\n",
    "                    height = f.readline().strip()\n",
    "                    logging.info(f\"video height = {height} pixels\")\n",
    "                    width = f.readline().strip()\n",
    "                    logging.info(f\"video width = {width} pixels\")\n",
    "                    BPP = float(f.readline().strip())\n",
    "                    logging.info(f\"BPP = {BPP}\")\n",
    "\n",
    "    def encode(self):\n",
    "        \"\"\"\n",
    "        Encode a video using MCTF.\n",
    "\n",
    "        Process:\n",
    "        1. Read frames from input video\n",
    "        2. Group frames into GOPs\n",
    "        3. For each GOP:\n",
    "           a. Estimate bidirectional motion\n",
    "           b. Apply temporal filtering (lifting)\n",
    "           c. Encode L and H frames with spatial transform\n",
    "        \"\"\"\n",
    "        logging.debug(\"trace\")\n",
    "        fn = self.args.video_input\n",
    "        logging.info(f\"MCTF Encoding {fn}\")\n",
    "\n",
    "        # Read video and extract frames\n",
    "        container = av.open(fn)\n",
    "        frames = []\n",
    "        img_counter = 0\n",
    "\n",
    "        for packet in container.demux():\n",
    "            if __debug__:\n",
    "                self.total_input_size += packet.size\n",
    "            for frame in packet.decode():\n",
    "                img = frame.to_image()\n",
    "                img_array = np.array(img.convert('L'))  # Grayscale for MCTF\n",
    "                frames.append(img_array)\n",
    "\n",
    "                # Save original for comparison\n",
    "                if __debug__:\n",
    "                    img_fn = os.path.join(TMP_DIR, f\"original_{img_counter:04d}.png\")\n",
    "                    img.save(img_fn)\n",
    "\n",
    "                img_counter += 1\n",
    "                if img_counter >= self.args.number_of_frames:\n",
    "                    break\n",
    "            if img_counter >= self.args.number_of_frames:\n",
    "                break\n",
    "\n",
    "        self.N_frames = len(frames)\n",
    "        self.height, self.width = frames[0].shape\n",
    "        logging.info(f\"Read {self.N_frames} frames of size {self.width}x{self.height}\")\n",
    "\n",
    "        # Process GOPs\n",
    "        gop_data_list = []\n",
    "        frame_idx = 0\n",
    "        gop_counter = 0\n",
    "\n",
    "        while frame_idx < self.N_frames:\n",
    "            gop_end = min(frame_idx + self.gop_size, self.N_frames)\n",
    "            gop_frames = frames[frame_idx:gop_end]\n",
    "\n",
    "            logging.info(f\"Processing GOP {gop_counter}: frames {frame_idx}-{gop_end-1}\")\n",
    "\n",
    "            # Encode GOP\n",
    "            gop_data = self._encode_gop(gop_frames, gop_counter)\n",
    "            gop_data_list.append(gop_data)\n",
    "\n",
    "            frame_idx = gop_end\n",
    "            gop_counter += 1\n",
    "\n",
    "        # Write encoded stream\n",
    "        self._write_mctf_stream(gop_data_list)\n",
    "\n",
    "        logging.info(f\"MCTF encoding complete: {gop_counter} GOPs\")\n",
    "\n",
    "    def _encode_gop(self, gop_frames, gop_idx):\n",
    "        \"\"\"Encode a GOP using MCTF.\"\"\"\n",
    "        n_frames = len(gop_frames)\n",
    "\n",
    "        if n_frames < 2:\n",
    "            # Very small GOP: encode as intra only\n",
    "            return self._encode_intra_only(gop_frames, gop_idx)\n",
    "\n",
    "        # === Step 1: Motion estimation ===\n",
    "        logging.info(f\"  Motion estimation for {n_frames} frames\")\n",
    "        mv_forward_list = []\n",
    "        mv_backward_list = []\n",
    "\n",
    "        for i in range(n_frames):\n",
    "            frame_current = gop_frames[i]\n",
    "            frame_prev = gop_frames[max(0, i - 1)]\n",
    "            frame_next = gop_frames[min(n_frames - 1, i + 1)]\n",
    "\n",
    "            mv_fwd, mv_bwd = block_matching_bidirectional(\n",
    "                frame_current, frame_prev, frame_next,\n",
    "                self.block_size, self.search_range\n",
    "            )\n",
    "            mv_forward_list.append(mv_fwd)\n",
    "            mv_backward_list.append(mv_bwd)\n",
    "\n",
    "        # === Step 2: Temporal filtering (lifting) ===\n",
    "        logging.info(f\"  Temporal filtering with {self.wavelet_type} wavelet\")\n",
    "        low_pass, high_pass = temporal_filter_lifting(\n",
    "            gop_frames,\n",
    "            mv_forward_list,\n",
    "            mv_backward_list,\n",
    "            self.wavelet_type,\n",
    "            self.block_size\n",
    "        )\n",
    "\n",
    "        # === Step 3: Encode L and H frames with spatial transform ===\n",
    "        logging.info(f\"  Encoding {len(low_pass)} L frames and {len(high_pass)} H frames\")\n",
    "\n",
    "        encoded_low = []\n",
    "        for i, l_frame in enumerate(low_pass):\n",
    "            l_frame_uint8 = np.clip(l_frame, 0, 255).astype(np.uint8)\n",
    "            fn_l = os.path.join(TMP_DIR, f\"gop{gop_idx:02d}_L_{i:02d}\")\n",
    "            self._save_and_encode_frame(l_frame_uint8, fn_l)\n",
    "            encoded_low.append(fn_l)\n",
    "\n",
    "        encoded_high = []\n",
    "        for i, h_frame in enumerate(high_pass):\n",
    "            # Residuals can be negative: offset to positive\n",
    "            h_frame_offset = h_frame + 128\n",
    "            h_frame_uint8 = np.clip(h_frame_offset, 0, 255).astype(np.uint8)\n",
    "            fn_h = os.path.join(TMP_DIR, f\"gop{gop_idx:02d}_H_{i:02d}\")\n",
    "            self._save_and_encode_frame(h_frame_uint8, fn_h)\n",
    "            encoded_high.append(fn_h)\n",
    "\n",
    "        return {\n",
    "            'n_frames': n_frames,\n",
    "            'mv_forward': mv_forward_list,\n",
    "            'mv_backward': mv_backward_list,\n",
    "            'encoded_low': encoded_low,\n",
    "            'encoded_high': encoded_high,\n",
    "            'wavelet_type': self.wavelet_type\n",
    "        }\n",
    "\n",
    "    def _encode_intra_only(self, frames, gop_idx):\n",
    "        \"\"\"Encode frames as intra only.\"\"\"\n",
    "        encoded_frames = []\n",
    "        for i, frame in enumerate(frames):\n",
    "            fn = os.path.join(TMP_DIR, f\"gop{gop_idx:02d}_I_{i:02d}\")\n",
    "            self._save_and_encode_frame(frame, fn)\n",
    "            encoded_frames.append(fn)\n",
    "\n",
    "        return {\n",
    "            'n_frames': len(frames),\n",
    "            'intra_only': True,\n",
    "            'encoded_frames': encoded_frames\n",
    "        }\n",
    "\n",
    "    def _save_and_encode_frame(self, frame, fn_prefix):\n",
    "        \"\"\"Save and encode a frame using TIFF with lossless compression.\"\"\"\n",
    "        # Convert to RGB if grayscale\n",
    "        if len(frame.shape) == 2:\n",
    "            frame_rgb = np.stack([frame] * 3, axis=-1)\n",
    "        else:\n",
    "            frame_rgb = frame\n",
    "\n",
    "        # Save as TIFF with lossless compression\n",
    "        img_fn = f\"{fn_prefix}.tif\"\n",
    "        img = Image.fromarray(frame_rgb)\n",
    "        img.save(img_fn, compression='tiff_deflate')\n",
    "\n",
    "        output_size = os.path.getsize(img_fn)\n",
    "        self.total_output_size += output_size\n",
    "        return output_size\n",
    "\n",
    "    def _write_mctf_stream(self, gop_data_list):\n",
    "        \"\"\"Write the encoded MCTF stream.\"\"\"\n",
    "        stream_fn = f\"{self.args.video_output}.mctf\"\n",
    "\n",
    "        header = {\n",
    "            'n_frames': self.N_frames,\n",
    "            'height': self.height,\n",
    "            'width': self.width,\n",
    "            'gop_size': self.gop_size,\n",
    "            'temporal_levels': self.temporal_levels,\n",
    "            'block_size': self.block_size,\n",
    "            'wavelet_type': self.wavelet_type,\n",
    "            'num_gops': len(gop_data_list)\n",
    "        }\n",
    "\n",
    "        with open(stream_fn, 'wb') as f:\n",
    "            pickle.dump(header, f)\n",
    "            for gop_data in gop_data_list:\n",
    "                pickle.dump(gop_data, f)\n",
    "\n",
    "        stream_size = os.path.getsize(stream_fn)\n",
    "        self.total_output_size += stream_size\n",
    "        logging.info(f\"Written MCTF stream: {stream_fn} ({stream_size} bytes)\")\n",
    "\n",
    "    def decode(self):\n",
    "        \"\"\"\n",
    "        Decode a video encoded with MCTF.\n",
    "\n",
    "        Inverse process:\n",
    "        1. Read MCTF stream\n",
    "        2. For each GOP:\n",
    "           a. Decode L and H frames with inverse spatial transform\n",
    "           b. Apply inverse temporal filtering (inverse lifting)\n",
    "        3. Write decoded frames\n",
    "        \"\"\"\n",
    "        logging.debug(\"trace\")\n",
    "        logging.info(f\"MCTF Decoding {self.args.video_input}\")\n",
    "\n",
    "        # Read MCTF stream\n",
    "        stream_fn = f\"{self.args.video_input}.mctf\"\n",
    "        header, gop_data_list = self._read_mctf_stream(stream_fn)\n",
    "\n",
    "        self.N_frames = header['n_frames']\n",
    "        self.height = header['height']\n",
    "        self.width = header['width']\n",
    "\n",
    "        logging.info(f\"Decoding {self.N_frames} frames of size {self.width}x{self.height}\")\n",
    "        logging.info(f\"  {header['num_gops']} GOPs\")\n",
    "\n",
    "        # Decode each GOP\n",
    "        all_frames = []\n",
    "        for gop_idx, gop_data in enumerate(gop_data_list):\n",
    "            logging.info(f\"Decoding GOP {gop_idx}\")\n",
    "\n",
    "            if gop_data.get('intra_only', False):\n",
    "                gop_frames = self._decode_intra_only(gop_data)\n",
    "            else:\n",
    "                gop_frames = self._decode_gop(gop_data)\n",
    "\n",
    "            all_frames.extend(gop_frames)\n",
    "\n",
    "        # Write decoded frames\n",
    "        for i, frame in enumerate(all_frames):\n",
    "            frame_uint8 = np.clip(frame, 0, 255).astype(np.uint8)\n",
    "            out_fn = os.path.join(TMP_DIR, f\"decoded_{i:04d}.png\")\n",
    "\n",
    "            if len(frame_uint8.shape) == 2:\n",
    "                frame_rgb = np.stack([frame_uint8] * 3, axis=-1)\n",
    "            else:\n",
    "                frame_rgb = frame_uint8\n",
    "\n",
    "            Image.fromarray(frame_rgb).save(out_fn)\n",
    "            logging.info(f\"Decoded frame {i} to {out_fn}\")\n",
    "\n",
    "        logging.info(f\"MCTF decoding complete: {len(all_frames)} frames\")\n",
    "\n",
    "    def _read_mctf_stream(self, stream_fn):\n",
    "        \"\"\"Read the encoded MCTF stream.\"\"\"\n",
    "        with open(stream_fn, 'rb') as f:\n",
    "            header = pickle.load(f)\n",
    "            gop_data_list = []\n",
    "            for _ in range(header['num_gops']):\n",
    "                gop_data = pickle.load(f)\n",
    "                gop_data_list.append(gop_data)\n",
    "\n",
    "        return header, gop_data_list\n",
    "\n",
    "    def _decode_gop(self, gop_data):\n",
    "        \"\"\"Decode a GOP using inverse MCTF.\"\"\"\n",
    "        n_frames = gop_data['n_frames']\n",
    "        mv_forward = gop_data['mv_forward']\n",
    "        mv_backward = gop_data['mv_backward']\n",
    "        wavelet_type = gop_data['wavelet_type']\n",
    "\n",
    "        # === Step 1: Decode L and H frames ===\n",
    "        logging.info(f\"  Decoding L and H frames\")\n",
    "\n",
    "        low_pass = []\n",
    "        for fn_l in gop_data['encoded_low']:\n",
    "            frame = self._decode_frame(fn_l)\n",
    "            low_pass.append(frame.astype(np.float32))\n",
    "\n",
    "        high_pass = []\n",
    "        for fn_h in gop_data['encoded_high']:\n",
    "            frame = self._decode_frame(fn_h)\n",
    "            # Remove offset added during encoding\n",
    "            frame_float = frame.astype(np.float32) - 128\n",
    "            high_pass.append(frame_float)\n",
    "\n",
    "        # === Step 2: Inverse temporal filtering ===\n",
    "        logging.info(f\"  Inverse temporal filtering with {wavelet_type} wavelet\")\n",
    "        reconstructed = inverse_temporal_filter_lifting(\n",
    "            low_pass,\n",
    "            high_pass,\n",
    "            mv_forward,\n",
    "            mv_backward,\n",
    "            wavelet_type,\n",
    "            self.block_size\n",
    "        )\n",
    "\n",
    "        return reconstructed\n",
    "\n",
    "    def _decode_intra_only(self, gop_data):\n",
    "        \"\"\"Decode intra-only frames.\"\"\"\n",
    "        frames = []\n",
    "        for fn in gop_data['encoded_frames']:\n",
    "            frame = self._decode_frame(fn)\n",
    "            frames.append(frame.astype(np.float32))\n",
    "        return frames\n",
    "\n",
    "    def _decode_frame(self, fn_prefix):\n",
    "        \"\"\"Decode a frame by reading the TIFF.\"\"\"\n",
    "        img_fn = f\"{fn_prefix}.tif\"\n",
    "\n",
    "        # Read frame from TIFF\n",
    "        img = Image.open(img_fn)\n",
    "        frame = np.array(img.convert('L'))  # Grayscale\n",
    "        return frame\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main.main(parser.parser, logging, CoDec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Usage within VCF\n",
    "\n",
    "This section demonstrates how to use the MCTF codec within the VCF framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-help-title",
   "metadata": {},
   "source": [
    "### 3.1 View Available Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "usage-help",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: MCTF.py [-h] [-g] {encode,decode} ...\n",
      "\n",
      "positional arguments:\n",
      "  {encode,decode}  You must specify one of the following subcomands:\n",
      "    encode         Compress data\n",
      "    decode         Uncompress data\n",
      "\n",
      "options:\n",
      "  -h, --help       show this help message and exit\n",
      "  -g, --debug      Output debug information (default: False)\n"
     ]
    }
   ],
   "source": [
    "# View available command-line options\n",
    "!python ../src/MCTF.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "usage-encode-help",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: MCTF.py encode [-h] [-V VIDEO_INPUT] [-O VIDEO_OUTPUT] [-T TRANSFORM]\n",
      "                      [-N NUMBER_OF_FRAMES] [--gop_size GOP_SIZE]\n",
      "                      [--temporal_levels TEMPORAL_LEVELS]\n",
      "                      [--block_size BLOCK_SIZE] [--search_range SEARCH_RANGE]\n",
      "                      [--wavelet_type WAVELET_TYPE]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -V VIDEO_INPUT, --video_input VIDEO_INPUT\n",
      "                        Input video (default: http://www.hpca.ual.es/~vruiz/vi\n",
      "                        deos/mobile_352x288x30x420x300.mp4)\n",
      "  -O VIDEO_OUTPUT, --video_output VIDEO_OUTPUT\n",
      "                        Output prefix (default: C:/tmp\\encoded)\n",
      "  -T TRANSFORM, --transform TRANSFORM\n",
      "                        2D-transform (default: 2D-DCT)\n",
      "  -N NUMBER_OF_FRAMES, --number_of_frames NUMBER_OF_FRAMES\n",
      "                        Number of frames to encode (default: 3)\n",
      "  --gop_size GOP_SIZE   GOP size (default: 16)\n",
      "  --temporal_levels TEMPORAL_LEVELS\n",
      "                        Temporal decomposition levels (default: 4)\n",
      "  --block_size BLOCK_SIZE\n",
      "                        Block size for motion estimation (default: 16)\n",
      "  --search_range SEARCH_RANGE\n",
      "                        Search range for motion estimation (default: 16)\n",
      "  --wavelet_type WAVELET_TYPE\n",
      "                        Temporal wavelet type: haar, 5/3, 9/7 (default: 5/3)\n"
     ]
    }
   ],
   "source": [
    "# View encoding options\n",
    "!python ../src/MCTF.py encode -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "usage-decode-help",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: MCTF.py decode [-h] [-V VIDEO_INPUT] [-O VIDEO_OUTPUT] [-T TRANSFORM]\n",
      "                      [-N NUMBER_OF_FRAMES] [--gop_size GOP_SIZE]\n",
      "                      [--temporal_levels TEMPORAL_LEVELS]\n",
      "                      [--block_size BLOCK_SIZE] [--search_range SEARCH_RANGE]\n",
      "                      [--wavelet_type WAVELET_TYPE]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -V VIDEO_INPUT, --video_input VIDEO_INPUT\n",
      "                        Input MCTF stream prefix (default: C:/tmp\\encoded)\n",
      "  -O VIDEO_OUTPUT, --video_output VIDEO_OUTPUT\n",
      "                        Output prefix (default: C:/tmp\\decoded)\n",
      "  -T TRANSFORM, --transform TRANSFORM\n",
      "                        2D-transform (default: 2D-DCT)\n",
      "  -N NUMBER_OF_FRAMES, --number_of_frames NUMBER_OF_FRAMES\n",
      "                        Number of frames to decode (default: 3)\n",
      "  --gop_size GOP_SIZE   GOP size (default: 16)\n",
      "  --temporal_levels TEMPORAL_LEVELS\n",
      "                        Temporal decomposition levels (default: 4)\n",
      "  --block_size BLOCK_SIZE\n",
      "                        Block size for motion estimation (default: 16)\n",
      "  --search_range SEARCH_RANGE\n",
      "                        Search range for motion estimation (default: 16)\n",
      "  --wavelet_type WAVELET_TYPE\n",
      "                        Temporal wavelet type: haar, 5/3, 9/7 (default: 5/3)\n"
     ]
    }
   ],
   "source": [
    "# View decoding options\n",
    "!python ../src/MCTF.py decode -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-encode-title",
   "metadata": {},
   "source": [
    "### 3.2 Encoding a Video\n",
    "\n",
    "The following cell encodes a video using MCTF with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "usage-encode",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main Namespace(debug=False, subparser_name='encode', video_input='http://www.hpca.ual.es/~vruiz/videos/mobile_352x288x30x420x300.mp4', video_output='C:/tmp\\\\encoded', transform='2D-DCT', number_of_frames=16, gop_size=16, temporal_levels=4, block_size=16, search_range=16, wavelet_type='5/3', block_size_DCT=8, color_transform='YCoCg', perceptual_quantization=False, Lambda=None, disable_subbands=False, quantizer='deadzone', QSS=32, entropy_image_codec='TIFF', original='C:/tmp\\\\original.png', encoded='C:/tmp\\\\encoded', func=<function encode at 0x0000027F779C0FE0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(INFO) MCTF: MCTF Codec initialized:\n",
      "(INFO) MCTF:   GOP size: 16\n",
      "(INFO) MCTF:   Temporal levels: 4\n",
      "(INFO) MCTF:   Block size: 16\n",
      "(INFO) MCTF:   Search range: 16\n",
      "(INFO) MCTF:   Wavelet type: 5/3\n",
      "(INFO) MCTF:   Spatial transform: 2D-DCT\n",
      "(INFO) MCTF: MCTF Encoding http://www.hpca.ual.es/~vruiz/videos/mobile_352x288x30x420x300.mp4\n",
      "(INFO) MCTF: Read 16 frames of size 352x288\n",
      "(INFO) MCTF: Processing GOP 0: frames 0-15\n",
      "(INFO) MCTF:   Motion estimation for 16 frames\n",
      "(INFO) MCTF:   Temporal filtering with 5/3 wavelet\n",
      "(INFO) temporal_filtering: Temporal filtering 16 frames with 5/3 wavelet\n",
      "(INFO) temporal_filtering: Temporal filtering complete: 8 L frames, 8 H frames\n",
      "(INFO) MCTF:   Encoding 8 L frames and 8 H frames\n",
      "(INFO) MCTF: Written MCTF stream: C:/tmp\\encoded.mctf (103251 bytes)\n",
      "(INFO) MCTF: MCTF encoding complete: 1 GOPs\n",
      "(INFO) MCTF: Output bit-rate = 13.090312302714647 bits/pixel\n"
     ]
    }
   ],
   "source": [
    "# Encode 16 frames with default parameters\n",
    "# (GOP size=16, block_size=16, wavelet=5/3)\n",
    "!python ../src/MCTF.py encode -N 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-encode-custom-title",
   "metadata": {},
   "source": [
    "### 3.3 Encoding with Custom Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "usage-encode-custom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main Namespace(debug=False, subparser_name='encode', video_input='http://www.hpca.ual.es/~vruiz/videos/mobile_352x288x30x420x300.mp4', video_output='C:/tmp\\\\encoded', transform='2D-DCT', number_of_frames=8, gop_size=8, temporal_levels=4, block_size=8, search_range=32, wavelet_type='9/7', block_size_DCT=8, color_transform='YCoCg', perceptual_quantization=False, Lambda=None, disable_subbands=False, quantizer='deadzone', QSS=32, entropy_image_codec='TIFF', original='C:/tmp\\\\original.png', encoded='C:/tmp\\\\encoded', func=<function encode at 0x000002BB97E90FE0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(INFO) MCTF: MCTF Codec initialized:\n",
      "(INFO) MCTF:   GOP size: 8\n",
      "(INFO) MCTF:   Temporal levels: 4\n",
      "(INFO) MCTF:   Block size: 8\n",
      "(INFO) MCTF:   Search range: 32\n",
      "(INFO) MCTF:   Wavelet type: 9/7\n",
      "(INFO) MCTF:   Spatial transform: 2D-DCT\n",
      "(INFO) MCTF: MCTF Encoding http://www.hpca.ual.es/~vruiz/videos/mobile_352x288x30x420x300.mp4\n",
      "(INFO) MCTF: Read 8 frames of size 352x288\n",
      "(INFO) MCTF: Processing GOP 0: frames 0-7\n",
      "(INFO) MCTF:   Motion estimation for 8 frames\n",
      "(INFO) MCTF:   Temporal filtering with 9/7 wavelet\n",
      "(INFO) temporal_filtering: Temporal filtering 8 frames with 9/7 wavelet\n",
      "(INFO) temporal_filtering: Temporal filtering complete: 4 L frames, 4 H frames\n",
      "(INFO) MCTF:   Encoding 4 L frames and 4 H frames\n",
      "(INFO) MCTF: Written MCTF stream: C:/tmp\\encoded.mctf (203884 bytes)\n",
      "(INFO) MCTF: MCTF encoding complete: 1 GOPs\n",
      "(INFO) MCTF: Output bit-rate = 14.383897569444445 bits/pixel\n"
     ]
    }
   ],
   "source": [
    "# Encode with custom parameters:\n",
    "# - 8 frames\n",
    "# - GOP size of 8\n",
    "# - Block size of 8 (smaller blocks for finer motion)\n",
    "# - Search range of 32 (larger search area)\n",
    "# - 9/7 wavelet (better compression, irreversible)\n",
    "!python ../src/MCTF.py encode -N 8 --gop_size 8 --block_size 8 --search_range 32 --wavelet_type 9/7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-decode-title",
   "metadata": {},
   "source": [
    "### 3.4 Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "usage-decode",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoising filter = no_filter\n",
      "main Namespace(debug=False, subparser_name='decode', video_input='C:/tmp\\\\encoded', video_output='C:/tmp\\\\decoded', transform='2D-DCT', number_of_frames=16, gop_size=16, temporal_levels=4, block_size=16, search_range=16, wavelet_type='5/3', block_size_DCT=8, color_transform='YCoCg', perceptual_quantization=False, disable_subbands=False, quantizer='deadzone', QSS=32, filter='no_filter', entropy_image_codec='TIFF', encoded='C:/tmp\\\\encoded', decoded='C:/tmp\\\\decoded.png', func=<function decode at 0x000001E6D51409A0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(INFO) MCTF: MCTF Codec initialized:\n",
      "(INFO) MCTF:   GOP size: 16\n",
      "(INFO) MCTF:   Temporal levels: 4\n",
      "(INFO) MCTF:   Block size: 16\n",
      "(INFO) MCTF:   Search range: 16\n",
      "(INFO) MCTF:   Wavelet type: 5/3\n",
      "(INFO) MCTF:   Spatial transform: 2D-DCT\n",
      "(INFO) MCTF: MCTF Decoding C:/tmp\\encoded\n",
      "(INFO) MCTF: Decoding 8 frames of size 352x288\n",
      "(INFO) MCTF:   1 GOPs\n",
      "(INFO) MCTF: Decoding GOP 0\n",
      "(INFO) MCTF:   Decoding L and H frames\n",
      "(INFO) MCTF:   Inverse temporal filtering with 9/7 wavelet\n",
      "(INFO) temporal_filtering: Inverse temporal filtering: 4 L frames, 4 H frames\n",
      "(INFO) temporal_filtering: Inverse temporal filtering complete: 8 frames\n",
      "(INFO) MCTF: Decoded frame 0 to C:/tmp\\decoded_0000.png\n",
      "(INFO) MCTF: Decoded frame 1 to C:/tmp\\decoded_0001.png\n",
      "(INFO) MCTF: Decoded frame 2 to C:/tmp\\decoded_0002.png\n",
      "(INFO) MCTF: Decoded frame 3 to C:/tmp\\decoded_0003.png\n",
      "(INFO) MCTF: Decoded frame 4 to C:/tmp\\decoded_0004.png\n",
      "(INFO) MCTF: Decoded frame 5 to C:/tmp\\decoded_0005.png\n",
      "(INFO) MCTF: Decoded frame 6 to C:/tmp\\decoded_0006.png\n",
      "(INFO) MCTF: Decoded frame 7 to C:/tmp\\decoded_0007.png\n",
      "(INFO) MCTF: MCTF decoding complete: 8 frames\n",
      "(INFO) MCTF: original_file = http://www.hpca.ual.es/~vruiz/videos/mobile_352x288x30x420x300.mp4\n",
      "(INFO) MCTF: N_frames = 8\n",
      "(INFO) MCTF: video height = 288 pixels\n",
      "(INFO) MCTF: video width = 352 pixels\n",
      "(INFO) MCTF: BPP = 14.383897569444445\n"
     ]
    }
   ],
   "source": [
    "# Decode the encoded video\n",
    "!python ../src/MCTF.py decode -N 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-summary",
   "metadata": {},
   "source": [
    "### 3.5 Summary of Parameters\n",
    "\n",
    "| Parameter | Description | Default | Recommended Values |\n",
    "|-----------|-------------|---------|--------------------|\n",
    "| `-N` | Number of frames | 30 | Depends on video length |\n",
    "| `--gop_size` | Frames per GOP | 16 | 8, 16, 32 (power of 2) |\n",
    "| `--block_size` | Motion estimation block size | 16 | 8, 16, 32 |\n",
    "| `--search_range` | Motion search range in pixels | 16 | 8, 16, 32, 64 |\n",
    "| `--wavelet_type` | Temporal wavelet | 5/3 | haar, 5/3, 9/7 |\n",
    "| `-T` | Spatial transform | MPNG | MPNG, 2D-DCT, 2D-DWT |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ea46c-7a2b-4d9b-9e72-4df642bf9b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
