{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a91d7cf",
   "metadata": {},
   "source": [
    "# MDCT - Modified Discrete Cosine Transform\n",
    "\n",
    "## Group Composition\n",
    "- **Pablo Gómez Rivas**\n",
    "- **Cristhian Ceballos Moreno**\n",
    "- **Víctor Fernández Díaz**\n",
    "\n",
    "## a) Theoretical Explanation\n",
    "\n",
    "### Modified Discrete Cosine Transform (MDCT)\n",
    "\n",
    "The **Modified Discrete Cosine Transform (MDCT)**, also known as the **Modulated Lapped Transform (MLT)**, is a biorthogonal transform that implements overlapped windows with 50% overlap.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- **Elimination of blocking artifacts**: Unlike standard DCT which processes independent blocks (causing edge artifacts), MDCT uses overlapped windows that smooth transitions between blocks.\n",
    "\n",
    "- **Mapping 2N to N**: The transform accepts 2N input samples and produces N output coefficients.\n",
    "\n",
    "- **Perfect reconstruction**: Using the Princen-Bradley condition ($w[n]^2 + w[n+N]^2 = 1$), exact reconstruction is guaranteed when applying overlap-add.\n",
    "\n",
    "- **Type-IV DCT basis**: Uses the type IV discrete cosine transform with time-domain aliasing.\n",
    "\n",
    "**Mathematical Formula:**\n",
    "\n",
    "$$X_k = \\sum_{n=0}^{2N-1} x_n \\cdot w_n \\cdot \\cos\\left(\\frac{\\pi}{N}(n + \\frac{N+1}{2})(k + \\frac{1}{2})\\right)$$\n",
    "\n",
    "where:\n",
    "- $x_n$: input samples (length 2N)\n",
    "- $w_n$: analysis window (sine window)\n",
    "- $k = 0, 1, ..., N-1$: coefficient index\n",
    "\n",
    "**Malvar Window:**\n",
    "\n",
    "The sinusoidal Malvar window (1992) is:\n",
    "\n",
    "$$w[n] = \\sin\\left(\\frac{\\pi}{2N}(n + 0.5)\\right)$$\n",
    "\n",
    "This window satisfies the perfect reconstruction condition with 50% overlap.\n",
    "\n",
    "**Reference:** H.S. Malvar, \"Signal Processing with Lapped Transforms\", Artech House, 1992\n",
    "\n",
    "## b) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ca4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/MDCT.py\n",
    "'''Exploiting spatial redundancy with the Modified Discrete Cosine Transform (MDCT).\n",
    "\n",
    "The MDCT uses overlapping windows (2N samples with 50% overlap) to eliminate\n",
    "blocking artifacts inherent in block-based transforms like DCT. Also known as\n",
    "Modulated Lapped Transform (MLT) in Malvar's work.\n",
    "\n",
    "Signal extension modes (symmetric/reflect) are used at image boundaries to\n",
    "minimize border artifacts, especially important for large block sizes.\n",
    "\n",
    "Reference: H.S. Malvar, \"Signal Processing with Lapped Transforms\", Artech House, 1992\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import logging\n",
    "import struct\n",
    "import importlib\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from scipy.fftpack import dct, idct\n",
    "from PIL import Image\n",
    "\n",
    "# Import resources from DCT implementation (reused for block processing)\n",
    "from DCT2D.block_DCT import analyze_image as space_analyze\n",
    "from DCT2D.block_DCT import synthesize_image as space_synthesize\n",
    "from DCT2D.block_DCT import get_subbands, get_blocks\n",
    "from color_transforms.YCoCg import from_RGB, to_RGB\n",
    "from information_theory import distortion\n",
    "import main\n",
    "\n",
    "# Write description before importing parser (parser.py tries to read it)\n",
    "os.makedirs(\"/tmp\", exist_ok=True)\n",
    "with open(\"/tmp/description.txt\", 'w') as f:\n",
    "    f.write(__doc__)\n",
    "\n",
    "# Load local parser safely\n",
    "import importlib.util\n",
    "import sys\n",
    "parser_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"parser.py\")\n",
    "spec = importlib.util.spec_from_file_location(\"local_parser\", parser_path)\n",
    "local_parser = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(local_parser)\n",
    "\n",
    "# Inject local parser into sys.modules for other modules\n",
    "sys.modules['parser'] = local_parser\n",
    "\n",
    "# Default settings\n",
    "default_block_size = 8\n",
    "default_CT = \"YCoCg\"\n",
    "perceptual_quantization = False\n",
    "disable_subbands = False\n",
    "\n",
    "# Add parser arguments\n",
    "local_parser.parser_encode.add_argument(\"-B\", \"--block_size_MDCT\", type=local_parser.int_or_str, \n",
    "                                        help=f\"Block size (default: {default_block_size})\", \n",
    "                                        default=default_block_size)\n",
    "local_parser.parser_encode.add_argument(\"-t\", \"--color_transform\", type=local_parser.int_or_str, \n",
    "                                        help=f\"Color transform (default: \\\"{default_CT}\\\")\", \n",
    "                                        default=default_CT)\n",
    "local_parser.parser_encode.add_argument(\"-p\", \"--perceptual_quantization\", action='store_true', \n",
    "                                        help=f\"Use perceptual quantization (default: \\\"{perceptual_quantization}\\\")\", \n",
    "                                        default=perceptual_quantization)\n",
    "local_parser.parser_encode.add_argument(\"-x\", \"--disable_subbands\", action='store_true', \n",
    "                                        help=f\"Disable the coefficients reordering in subbands (default: \\\"{disable_subbands}\\\")\", \n",
    "                                        default=disable_subbands)\n",
    "\n",
    "local_parser.parser_decode.add_argument(\"-B\", \"--block_size_MDCT\", type=local_parser.int_or_str, \n",
    "                                        help=f\"Block size (default: {default_block_size})\", \n",
    "                                        default=default_block_size)\n",
    "local_parser.parser_decode.add_argument(\"-t\", \"--color_transform\", type=local_parser.int_or_str, \n",
    "                                        help=f\"Color transform (default: \\\"{default_CT}\\\")\", \n",
    "                                        default=default_CT)\n",
    "local_parser.parser_decode.add_argument(\"-p\", \"--perceptual_quantization\", action='store_true', \n",
    "                                        help=f\"Use perceptual dequantization (default: \\\"{perceptual_quantization}\\\")\", \n",
    "                                        default=perceptual_quantization)\n",
    "local_parser.parser_decode.add_argument(\"-x\", \"--disable_subbands\", action='store_true', \n",
    "                                        help=f\"Disable the coefficients reordering in subbands (default: \\\"{disable_subbands}\\\")\", \n",
    "                                        default=disable_subbands)\n",
    "\n",
    "args = local_parser.parser.parse_known_args()[0]\n",
    "CT = importlib.import_module(args.color_transform)\n",
    "\n",
    "# =============================================================================\n",
    "# MLT/MDCT Implementation (Malvar's Lapped Transform)\n",
    "# =============================================================================\n",
    "\n",
    "def create_mdct_window(N):\n",
    "    \"\"\"\n",
    "    Create the sine window for MDCT (Malvar's standard window).\n",
    "    \n",
    "    The sine window satisfies the Princen-Bradley condition for\n",
    "    perfect reconstruction: w[n]^2 + w[n+N]^2 = 1\n",
    "    \n",
    "    Parameters:\n",
    "        N (int): Block size (window is 2N samples).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Window of length 2N.\n",
    "    \"\"\"\n",
    "    n = np.arange(2 * N)\n",
    "    window = np.sin(np.pi * (n + 0.5) / (2 * N))\n",
    "    return window\n",
    "\n",
    "\n",
    "def mdct_1d(x, N):\n",
    "    \"\"\"\n",
    "    Compute the Modified Discrete Cosine Transform (MDCT) - Vectorized.\n",
    "    \n",
    "    MDCT maps 2N input samples to N output coefficients.\n",
    "    Uses the Type-IV DCT basis with time-domain aliasing.\n",
    "    \n",
    "    Parameters:\n",
    "        x (np.ndarray): Input signal (length 2N, windowed).\n",
    "        N (int): Block size (output length).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: MDCT coefficients (length N).\n",
    "    \"\"\"\n",
    "    n0 = (N + 1) / 2\n",
    "    # Vectorized computation: create matrices for n and k\n",
    "    n = np.arange(2 * N)\n",
    "    k = np.arange(N)\n",
    "    # Compute cosine matrix (N x 2N)\n",
    "    cos_matrix = np.cos(np.pi / N * (n + n0) * (k[:, np.newaxis] + 0.5))\n",
    "    # Apply matrix multiplication: dot product of cosine matrix with signal\n",
    "    X = np.dot(cos_matrix, x)\n",
    "    return X\n",
    "\n",
    "\n",
    "def imdct_1d(X, N):\n",
    "    \"\"\"\n",
    "    Compute the Inverse MDCT - Vectorized.\n",
    "    \n",
    "    IMDCT maps N coefficients to 2N output samples.\n",
    "    Perfect reconstruction requires overlap-add with adjacent blocks.\n",
    "    \n",
    "    Parameters:\n",
    "        X (np.ndarray): MDCT coefficients (length N).\n",
    "        N (int): Block size.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Reconstructed signal (length 2N).\n",
    "    \"\"\"\n",
    "    n0 = (N + 1) / 2\n",
    "    # Vectorized computation: create matrices for n and k\n",
    "    n = np.arange(2 * N)\n",
    "    k = np.arange(N)\n",
    "    # Compute cosine matrix (2N x N)\n",
    "    cos_matrix = np.cos(np.pi / N * (n[:, np.newaxis] + n0) * (k + 0.5))\n",
    "    # Apply matrix multiplication: dot product of cosine matrix with coefficients\n",
    "    x = np.dot(cos_matrix, X) * 2 / N\n",
    "    return x\n",
    "\n",
    "\n",
    "def mdct_analyze_1d(signal, N, extension_mode='symmetric'):\n",
    "    \"\"\"\n",
    "    Apply MDCT analysis to a 1D signal.\n",
    "    \n",
    "    Divides signal into overlapping blocks, applies window, computes MDCT.\n",
    "    Uses signal extension at boundaries to minimize border artifacts.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (np.ndarray): Input 1D signal.\n",
    "        N (int): Block size.\n",
    "        extension_mode (str): Signal extension mode for boundaries.\n",
    "            Options: 'symmetric', 'reflect', 'periodic', 'constant', 'zero'\n",
    "            Default: 'symmetric' (best for natural images)\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: MDCT coefficients (same length as input).\n",
    "    \"\"\"\n",
    "    L = len(signal)\n",
    "    # Extend signal using specified mode to minimize border artifacts\n",
    "    # This is crucial for large block sizes\n",
    "    if extension_mode == 'symmetric':\n",
    "        # Symmetric padding: ... x2 x1 | x1 x2 ... xn | xn xn-1 ...\n",
    "        padded = np.pad(signal, (N, N), mode='symmetric')\n",
    "    elif extension_mode == 'reflect':\n",
    "        # Reflect padding: ... x3 x2 | x1 x2 ... xn | xn-1 xn-2 ...\n",
    "        padded = np.pad(signal, (N, N), mode='reflect')\n",
    "    elif extension_mode == 'periodic':\n",
    "        # Periodic padding: ... xn-1 xn | x1 x2 ... xn | x1 x2 ...\n",
    "        padded = np.pad(signal, (N, N), mode='wrap')\n",
    "    elif extension_mode == 'constant':\n",
    "        # Constant padding: border values replicated\n",
    "        padded = np.pad(signal, (N, N), mode='edge')\n",
    "    else:\n",
    "        # Zero padding (original behavior, causes border artifacts)\n",
    "        padded = np.zeros(L + 2 * N)\n",
    "        padded[N:N + L] = signal\n",
    "    \n",
    "    window = create_mdct_window(N)\n",
    "    num_blocks = L // N\n",
    "    coeffs = np.zeros(L)\n",
    "    \n",
    "    for b in range(num_blocks):\n",
    "        start = b * N\n",
    "        # Extract 2N samples with 50% overlap\n",
    "        block = padded[start:start + 2 * N].copy()\n",
    "        # Apply analysis window\n",
    "        block *= window\n",
    "        # Compute MDCT\n",
    "        X = mdct_1d(block, N)\n",
    "        # Store N coefficients\n",
    "        coeffs[b * N:(b + 1) * N] = X\n",
    "    \n",
    "    return coeffs\n",
    "\n",
    "\n",
    "def mdct_synthesize_1d(coeffs, N, extension_mode='symmetric'):\n",
    "    \"\"\"\n",
    "    Apply MDCT synthesis to reconstruct a 1D signal.\n",
    "    \n",
    "    Computes IMDCT for each block, applies window, overlap-adds.\n",
    "    The extension_mode parameter should match the one used in analysis.\n",
    "    \n",
    "    Parameters:\n",
    "        coeffs (np.ndarray): MDCT coefficients.\n",
    "        N (int): Block size.\n",
    "        extension_mode (str): Signal extension mode (should match analysis).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Reconstructed 1D signal.\n",
    "    \"\"\"\n",
    "    L = len(coeffs)\n",
    "    window = create_mdct_window(N)\n",
    "    num_blocks = L // N\n",
    "    \n",
    "    # Output buffer with padding for overlap-add\n",
    "    output = np.zeros(L + 2 * N)\n",
    "    \n",
    "    for b in range(num_blocks):\n",
    "        # Get N coefficients for this block\n",
    "        X = coeffs[b * N:(b + 1) * N]\n",
    "        # Compute IMDCT (produces 2N samples)\n",
    "        block = imdct_1d(X, N)\n",
    "        # Apply synthesis window\n",
    "        block *= window\n",
    "        # Overlap-add\n",
    "        start = b * N\n",
    "        output[start:start + 2 * N] += block\n",
    "    \n",
    "    # Extract the valid portion\n",
    "    return output[N:N + L]\n",
    "\n",
    "\n",
    "def mdct_analyze_2d(img, N, extension_mode='symmetric'):\n",
    "    \"\"\"\n",
    "    Apply 2D MDCT analysis (separable: rows then columns).\n",
    "    \n",
    "    Uses signal extension at image boundaries to minimize border artifacts,\n",
    "    which is especially important for large block sizes.\n",
    "    \n",
    "    Parameters:\n",
    "        img (np.ndarray): Input image (H x W x C).\n",
    "        N (int): Block size.\n",
    "        extension_mode (str): Signal extension mode ('symmetric', 'reflect', etc.)\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: MDCT coefficients.\n",
    "    \"\"\"\n",
    "    h, w, c = img.shape\n",
    "    output = img.astype(np.float64).copy()\n",
    "    \n",
    "    # Apply to rows\n",
    "    for ch in range(c):\n",
    "        for row in range(h):\n",
    "            output[row, :, ch] = mdct_analyze_1d(output[row, :, ch], N, extension_mode)\n",
    "    \n",
    "    # Apply to columns\n",
    "    for ch in range(c):\n",
    "        for col in range(w):\n",
    "            output[:, col, ch] = mdct_analyze_1d(output[:, col, ch], N, extension_mode)\n",
    "    \n",
    "    return output.astype(np.float32)\n",
    "\n",
    "\n",
    "def mdct_synthesize_2d(coeffs, N, extension_mode='symmetric'):\n",
    "    \"\"\"\n",
    "    Apply 2D MDCT synthesis (separable: columns then rows).\n",
    "    \n",
    "    The extension_mode should match the one used in mdct_analyze_2d.\n",
    "    \n",
    "    Parameters:\n",
    "        coeffs (np.ndarray): MDCT coefficients (H x W x C).\n",
    "        N (int): Block size.\n",
    "        extension_mode (str): Signal extension mode (should match analysis).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Reconstructed image.\n",
    "    \"\"\"\n",
    "    h, w, c = coeffs.shape\n",
    "    output = coeffs.astype(np.float64).copy()\n",
    "    \n",
    "    # Reverse order: columns first\n",
    "    for ch in range(c):\n",
    "        for col in range(w):\n",
    "            output[:, col, ch] = mdct_synthesize_1d(output[:, col, ch], N, extension_mode)\n",
    "    \n",
    "    # Then rows\n",
    "    for ch in range(c):\n",
    "        for row in range(h):\n",
    "            output[row, :, ch] = mdct_synthesize_1d(output[row, :, ch], N, extension_mode)\n",
    "    \n",
    "    return output.astype(np.float32)\n",
    "\n",
    "\n",
    "def calculate_rmse(image1_path, image2_path):\n",
    "    \"\"\"\n",
    "    Calculate Root Mean Square Error (RMSE) between two images.\n",
    "    \"\"\"\n",
    "    img1 = Image.open(image1_path)\n",
    "    img2 = Image.open(image2_path)\n",
    "    \n",
    "    arr1 = np.array(img1, dtype=np.float32)\n",
    "    arr2 = np.array(img2, dtype=np.float32)\n",
    "    \n",
    "    if arr1.shape != arr2.shape:\n",
    "        logging.warning(f\"Image dimensions do not match: {arr1.shape} vs {arr2.shape}\")\n",
    "        return None, None\n",
    "    \n",
    "    mse = np.mean((arr1 - arr2) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse, arr1.shape\n",
    "\n",
    "\n",
    "def get_file_size(file_path):\n",
    "    \"\"\"\n",
    "    Get file size in bytes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return os.path.getsize(file_path)\n",
    "    except FileNotFoundError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def calculate_J(original_path, codestream_prefix, decoded_path):\n",
    "    \"\"\"\n",
    "    Calculate the Rate/Distortion efficiency (J = R + D).\n",
    "    \n",
    "    Parameters:\n",
    "        original_path (str): Path to original image\n",
    "        codestream_prefix (str): Prefix for codestream files (without extension)\n",
    "        decoded_path (str): Path to decoded image\n",
    "    \n",
    "    Returns:\n",
    "        float: J value (R + D), or None if calculation fails\n",
    "    \"\"\"\n",
    "    # Calculate RMSE\n",
    "    rmse, shape = calculate_rmse(original_path, decoded_path)\n",
    "    if rmse is None:\n",
    "        return None\n",
    "    \n",
    "    # Calculate codestream size in bytes\n",
    "    codestream_pattern = codestream_prefix + '*'\n",
    "    codestream_files = glob.glob(codestream_pattern)\n",
    "    codestream_bytes = sum(get_file_size(f) for f in codestream_files)\n",
    "    \n",
    "    # Calculate bits per pixel\n",
    "    if shape is None:\n",
    "        return None\n",
    "    number_of_pixels = shape[0] * shape[1]\n",
    "    codestream_bpp = (codestream_bytes * 8) / number_of_pixels\n",
    "    \n",
    "    # Calculate J\n",
    "    J = codestream_bpp + rmse\n",
    "    \n",
    "    logging.info(f\"=== Rate/Distortion Efficiency ===\")\n",
    "    logging.info(f\"Original: {original_path}\")\n",
    "    logging.info(f\"Codestream files: {codestream_files}\")\n",
    "    logging.info(f\"Codestream size: {codestream_bytes} bytes ({codestream_bpp:.2f} bits/pixel)\")\n",
    "    logging.info(f\"Decoded: {decoded_path}\")\n",
    "    logging.info(f\"Image shape: {shape}\")\n",
    "    logging.info(f\"Distortion (RMSE): {rmse:.2f}\")\n",
    "    logging.info(f\"J = R + D = {codestream_bpp:.2f} + {rmse:.2f} = {J:.2f}\")\n",
    "    \n",
    "    return J\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MDCT CoDec Class - Uses MDCT (Malvar's Lapped Transform)\n",
    "# =============================================================================\n",
    "\n",
    "class CoDec(CT.CoDec):\n",
    "    \"\"\"\n",
    "    Codec using MDCT (Modified Discrete Cosine Transform).\n",
    "    \n",
    "    This implements Malvar's Modulated Lapped Transform, which is the\n",
    "    theoretically correct way to eliminate blocking artifacts. The MDCT:\n",
    "    - Uses 50% overlapping windows\n",
    "    - Provides perfect reconstruction (without quantization)\n",
    "    - Is critically sampled (same number of coefficients as samples)\n",
    "    - Is used in MP3, AAC, Vorbis, and other successful codecs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        logging.debug(\"trace\")\n",
    "        super().__init__(args)\n",
    "        self.args = args\n",
    "        self.block_size = args.block_size_MDCT\n",
    "        self.use_mdct = True\n",
    "        # MDCT scaling factor: Empirically determined to match DCT coefficient range\n",
    "        # Different strategies for different quantizers:\n",
    "        # - deadzone: Works well with moderate scaling\n",
    "        # - LloydMax: Needs precise DCT-equivalent scaling\n",
    "        # For LloydMax, we need to match DCT's statistical distribution exactly\n",
    "        if args.quantizer == \"LloydMax\":\n",
    "            # For LloydMax, use a more aggressive scaling to match DCT range\n",
    "            # Empirically: DCT coeffs are in ~[-1000, 1000], MDCT in ~[-350, 1676]\n",
    "            # Ratio: MDCT/DCT ≈ 1.5-2x, so scale by block_size/1.5\n",
    "            self.mdct_scale_factor = float(self.block_size) / 1.5\n",
    "        elif self.block_size <= 8:\n",
    "            self.mdct_scale_factor = float(self.block_size) / 2.0\n",
    "        elif self.block_size >= 32:\n",
    "            self.mdct_scale_factor = float(self.block_size) / 4.0\n",
    "        else:\n",
    "            # Linear interpolation between 8 and 32\n",
    "            t = (self.block_size - 8) / (32 - 8)\n",
    "            scale_8 = 8.0 / 2.0\n",
    "            scale_32 = 32.0 / 4.0\n",
    "            self.mdct_scale_factor = scale_8 + t * (scale_32 - scale_8)\n",
    "        \n",
    "        logging.info(f\"MDCT: block_size = {self.block_size}, scale_factor = {self.mdct_scale_factor:.2f}, quantizer = {args.quantizer}\")\n",
    "        logging.debug(f\"block_size = {self.block_size}\")\n",
    "        logging.debug(f\"MDCT scale factor = {self.mdct_scale_factor:.2f}\")\n",
    "\n",
    "        if args.perceptual_quantization:\n",
    "            # JPEG standard quantization matrices\n",
    "            self.Y_QSSs = np.array([[16,11,10,16,24,40,51,61],[12,12,14,19,26,58,60,55],\n",
    "                                    [14,13,16,24,40,57,69,56],[14,17,22,29,51,87,80,62],\n",
    "                                    [18,22,37,56,68,109,103,77],[24,35,55,64,81,104,113,92],\n",
    "                                    [49,64,78,87,103,121,120,101],[72,92,95,98,112,100,103,99]]).astype(np.float32)\n",
    "            self.C_QSSs = np.array([[17,18,24,47,99,99,99,99],[18,21,26,66,99,99,99,99],\n",
    "                                    [24,26,56,99,99,99,99,99],[47,66,99,99,99,99,99,99],\n",
    "                                    [99,99,99,99,99,99,99,99],[99,99,99,99,99,99,99,99],\n",
    "                                    [99,99,99,99,99,99,99,99],[99,99,99,99,99,99,99,99]]).astype(np.float32)\n",
    "            inter = cv2.INTER_AREA if self.block_size < 8 else cv2.INTER_LINEAR\n",
    "            self.C_QSSs = cv2.resize(self.C_QSSs, (self.block_size, self.block_size), interpolation=inter).astype(np.float32)\n",
    "            self.Y_QSSs = cv2.resize(self.Y_QSSs, (self.block_size, self.block_size), interpolation=inter).astype(np.float32)\n",
    "            \n",
    "            self.Y_QSSs_max = np.max(self.Y_QSSs) if np.max(self.Y_QSSs) > 0 else 1.0\n",
    "            self.C_QSSs_max = np.max(self.C_QSSs) if np.max(self.C_QSSs) > 0 else 1.0\n",
    "\n",
    "        self.offset = 128 if args.quantizer == \"deadzone\" else 0\n",
    "\n",
    "    def pad_and_center_to_multiple_of_block_size(self, img):\n",
    "        \"\"\"\n",
    "        Pad image to multiple of block size, centering the original content.\n",
    "        Uses symmetric extension to minimize border artifacts.\n",
    "        Extended padding (2*block_size) ensures MDCT has enough context at borders.\n",
    "        \"\"\"\n",
    "        logging.debug(\"trace\")\n",
    "        if img.ndim != 3:\n",
    "            raise ValueError(\"Input image must be a 3D array.\")\n",
    "        self.original_shape = img.shape\n",
    "        h, w, c = img.shape\n",
    "        \n",
    "        # Calculate target size: multiple of block_size, plus extra for MDCT overlap\n",
    "        # Add block_size on each side to ensure proper MDCT context at boundaries\n",
    "        extra_pad = self.block_size\n",
    "        th = ((h + 2*extra_pad + self.block_size - 1) // self.block_size) * self.block_size\n",
    "        tw = ((w + 2*extra_pad + self.block_size - 1) // self.block_size) * self.block_size\n",
    "        \n",
    "        ph, pw = th - h, tw - w\n",
    "        top, left = ph // 2, pw // 2\n",
    "        \n",
    "        # Use symmetric padding to reduce border artifacts\n",
    "        # This mirrors the signal at boundaries, providing smooth continuation\n",
    "        padded_img = np.pad(img, ((top, ph-top), (left, pw-left), (0,0)), mode='symmetric')\n",
    "        \n",
    "        # Store padding info for removal\n",
    "        self.pad_top = top\n",
    "        self.pad_left = left\n",
    "        self.padded_shape = padded_img.shape\n",
    "        \n",
    "        return padded_img\n",
    "\n",
    "    def remove_padding(self, img):\n",
    "        \"\"\"\n",
    "        Remove padding from image to restore original dimensions.\n",
    "        \"\"\"\n",
    "        logging.debug(\"trace\")\n",
    "        if img.ndim != 3:\n",
    "            raise ValueError(\"Input must be 3D.\")\n",
    "        if self.original_shape is None:\n",
    "            raise ValueError(\"Original shape not set.\")\n",
    "        oh, ow, _ = self.original_shape\n",
    "        \n",
    "        # Use stored padding info if available, otherwise calculate\n",
    "        if hasattr(self, 'pad_top') and hasattr(self, 'pad_left'):\n",
    "            top, left = self.pad_top, self.pad_left\n",
    "        else:\n",
    "            ph, pw, _ = img.shape\n",
    "            top, left = (ph - oh)//2, (pw - ow)//2\n",
    "        \n",
    "        return img[top:top+oh, left:left+ow, :]\n",
    "\n",
    "    def encode_fn(self, in_fn, out_fn):\n",
    "        \"\"\"\n",
    "        Encode image using MDCT (Malvar's Lapped Transform).\n",
    "        \"\"\"\n",
    "        logging.debug(\"trace\")\n",
    "        # Force INFO logging for diagnostics\n",
    "        logging.getLogger().setLevel(logging.INFO)\n",
    "        img = self.encode_read_fn(in_fn).astype(np.float32)\n",
    "        self.original_shape = img.shape\n",
    "        img = self.pad_and_center_to_multiple_of_block_size(img)\n",
    "        \n",
    "        # Save original shape and padding info\n",
    "        with open(f\"{out_fn}_shape.bin\", \"wb\") as f:\n",
    "            f.write(struct.pack(\"iii\", *self.original_shape))\n",
    "            f.write(struct.pack(\"ii\", self.pad_top, self.pad_left))\n",
    "        \n",
    "        # Follow DCT pattern: subtract offset BEFORE transform\n",
    "        img -= self.offset\n",
    "        \n",
    "        # Color transform: RGB → YCoCg\n",
    "        ct_img = from_RGB(img)\n",
    "        \n",
    "        # MDCT analysis\n",
    "        if self.use_mdct:\n",
    "            mdct_coeffs = mdct_analyze_2d(ct_img, self.block_size)\n",
    "            # Normalize MDCT coefficients to match DCT range\n",
    "            mdct_coeffs /= self.mdct_scale_factor\n",
    "        else:\n",
    "            mdct_coeffs = space_analyze(ct_img, self.block_size, self.block_size)\n",
    "        \n",
    "        # DEBUG: Print coefficient statistics\n",
    "        logging.info(f\"MDCT coeffs after transform: min={np.min(mdct_coeffs):.2f}, max={np.max(mdct_coeffs):.2f}, mean={np.mean(mdct_coeffs):.2f}, std={np.std(mdct_coeffs):.2f}\")\n",
    "\n",
    "        # Perceptual quantization scaling BEFORE subbands\n",
    "        if self.args.perceptual_quantization:\n",
    "            logging.debug(f\"Using perceptual quantization with block_size = {self.block_size}\")\n",
    "            mdct_coeffs = mdct_coeffs.astype(np.float32)\n",
    "            blocks_in_y = int(ct_img.shape[0]/self.block_size)\n",
    "            blocks_in_x = int(ct_img.shape[1]/self.block_size)\n",
    "            for by in range(blocks_in_y):\n",
    "                for bx in range(blocks_in_x):\n",
    "                    y_start = by*self.block_size\n",
    "                    y_end = (by+1)*self.block_size\n",
    "                    x_start = bx*self.block_size\n",
    "                    x_end = (bx+1)*self.block_size\n",
    "                    # Multiply by (QSSs/max) like DCT\n",
    "                    mdct_coeffs[y_start:y_end, x_start:x_end, 0] *= (self.Y_QSSs/self.Y_QSSs_max)\n",
    "                    mdct_coeffs[y_start:y_end, x_start:x_end, 1] *= (self.C_QSSs/self.C_QSSs_max)\n",
    "                    mdct_coeffs[y_start:y_end, x_start:x_end, 2] *= (self.C_QSSs/self.C_QSSs_max)\n",
    "            \n",
    "            # DEBUG: Print after perceptual scaling\n",
    "            logging.info(f\"MDCT coeffs after perceptual: min={np.min(mdct_coeffs):.2f}, max={np.max(mdct_coeffs):.2f}, mean={np.mean(mdct_coeffs):.2f}, std={np.std(mdct_coeffs):.2f}\")\n",
    "\n",
    "        # Coefficients reordering in subbands\n",
    "        if self.args.disable_subbands:\n",
    "            decom_img = mdct_coeffs\n",
    "        else:\n",
    "            decom_img = get_subbands(mdct_coeffs, self.block_size, self.block_size)\n",
    "        \n",
    "        # DEBUG: Print before quantization\n",
    "        logging.info(f\"Before quantization: min={np.min(decom_img):.2f}, max={np.max(decom_img):.2f}, mean={np.mean(decom_img):.2f}, std={np.std(decom_img):.2f}\")\n",
    "\n",
    "        # Quantization and compression\n",
    "        decom_k = self.quantize_decom(decom_img)\n",
    "        \n",
    "        # DEBUG: Print quantization output\n",
    "        logging.info(f\"After quantization: min={np.min(decom_k):.2f}, max={np.max(decom_k):.2f}, mean={np.mean(decom_k):.2f}\")\n",
    "        \n",
    "        # Handle different quantizers appropriately\n",
    "        if self.args.quantizer == \"LloydMax\":\n",
    "            # LloydMax returns indices in [0, QSS-1], which fits in uint8 if QSS <= 256\n",
    "            # No offset needed, just ensure proper type\n",
    "            if self.args.QSS <= 256:\n",
    "                decom_k = np.clip(decom_k, 0, 255).astype(np.uint8)\n",
    "            else:\n",
    "                # For QSS > 256, use uint16\n",
    "                decom_k = np.clip(decom_k, 0, 65535).astype(np.uint16)\n",
    "        else:\n",
    "            # Deadzone quantizer: add offset and clip to [0, 255]\n",
    "            decom_k += self.offset\n",
    "            decom_k = np.clip(decom_k, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        decom_k = self.compress(decom_k)\n",
    "        output_size = self.encode_write_fn(decom_k, out_fn)\n",
    "        return output_size\n",
    "\n",
    "    def encode(self, in_fn=\"/tmp/original.png\", out_fn=\"/tmp/encoded\"):\n",
    "        return self.encode_fn(in_fn, out_fn)\n",
    "\n",
    "    def decode_fn(self, in_fn, out_fn):\n",
    "        \"\"\"\n",
    "        Decode code-stream using MDCT (Malvar's Lapped Transform).\n",
    "        \"\"\"\n",
    "        logging.debug(\"trace\")\n",
    "        decom_k = self.decode_read_fn(in_fn)\n",
    "        \n",
    "        # Read original shape and padding info\n",
    "        with open(f\"{in_fn}_shape.bin\", \"rb\") as f:\n",
    "            self.original_shape = struct.unpack(\"iii\", f.read(12))\n",
    "            try:\n",
    "                self.pad_top, self.pad_left = struct.unpack(\"ii\", f.read(8))\n",
    "            except struct.error:\n",
    "                # Fallback for old format without padding info\n",
    "                self.pad_top = None\n",
    "                self.pad_left = None\n",
    "        \n",
    "        # Decompress and dequantize\n",
    "        decom_k = self.decompress(decom_k)\n",
    "        \n",
    "        # Handle different quantizers appropriately in decode\n",
    "        if self.args.quantizer == \"LloydMax\":\n",
    "            # LloydMax: indices are already in correct range, no offset to remove\n",
    "            decom_k = decom_k.astype(np.int16)\n",
    "        else:\n",
    "            # Deadzone: remove offset\n",
    "            decom_k = decom_k.astype(np.int16)\n",
    "            decom_k -= self.offset\n",
    "        \n",
    "        # DEBUG: Print after decompression\n",
    "        logging.info(f\"After decompression: min={np.min(decom_k):.2f}, max={np.max(decom_k):.2f}, mean={np.mean(decom_k):.2f}\")\n",
    "        \n",
    "        decom_y = self.dequantize_decom(decom_k)\n",
    "        \n",
    "        # Reconstruct blocks from subbands\n",
    "        if self.args.disable_subbands:\n",
    "            mdct_coeffs = decom_y\n",
    "        else:\n",
    "            mdct_coeffs = get_blocks(decom_y, self.block_size, self.block_size)\n",
    "        \n",
    "        # Perceptual dequantization\n",
    "        if self.args.perceptual_quantization:\n",
    "            logging.debug(f\"Using perceptual dequantization with block_size = {self.block_size}\")\n",
    "            mdct_coeffs = mdct_coeffs.astype(np.float32)\n",
    "            blocks_in_y = int(mdct_coeffs.shape[0]/self.block_size)\n",
    "            blocks_in_x = int(mdct_coeffs.shape[1]/self.block_size)\n",
    "            for by in range(blocks_in_y):\n",
    "                for bx in range(blocks_in_x):\n",
    "                    y_start = by*self.block_size\n",
    "                    y_end = (by+1)*self.block_size\n",
    "                    x_start = bx*self.block_size\n",
    "                    x_end = (bx+1)*self.block_size\n",
    "                    \n",
    "                    mdct_coeffs[y_start:y_end, x_start:x_end, 0] /= (self.Y_QSSs/self.Y_QSSs_max)\n",
    "                    mdct_coeffs[y_start:y_end, x_start:x_end, 1] /= (self.C_QSSs/self.C_QSSs_max)\n",
    "                    mdct_coeffs[y_start:y_end, x_start:x_end, 2] /= (self.C_QSSs/self.C_QSSs_max)\n",
    "        \n",
    "        # IMDCT synthesis\n",
    "        if self.use_mdct:\n",
    "            ct_y = mdct_synthesize_2d(mdct_coeffs, self.block_size)\n",
    "            # Denormalize to restore original scale\n",
    "            ct_y *= self.mdct_scale_factor\n",
    "        else:\n",
    "            ct_y = space_synthesize(mdct_coeffs, self.block_size, self.block_size)\n",
    "        \n",
    "        # Inverse color transform: YCoCg → RGB\n",
    "        y = to_RGB(ct_y)\n",
    "        \n",
    "        # Remove padding and add offset back\n",
    "        y = self.remove_padding(y)\n",
    "        y += self.offset\n",
    "        y = np.clip(y, 0, 255).astype(np.uint8)\n",
    "        output_size = self.decode_write_fn(y, out_fn)\n",
    "        \n",
    "        # Calculate and log J (Rate/Distortion Efficiency)\n",
    "        J = calculate_J(\"/tmp/original.png\", in_fn, out_fn)\n",
    "        if J is not None:\n",
    "            logging.info(f\"Rate/Distortion Efficiency: J = {J:.2f}\")\n",
    "        \n",
    "        return output_size\n",
    "\n",
    "    def decode(self, in_fn=\"/tmp/encoded\", out_fn=\"/tmp/decoded.png\"):\n",
    "        return self.decode_fn(in_fn, out_fn)\n",
    "\n",
    "    def quantize_decom(self, decom):\n",
    "        logging.debug(\"trace\")\n",
    "        result = self.quantize(decom)\n",
    "        # DEBUG: Check quantization output\n",
    "        logging.info(f\"quantize_decom output: min={np.min(result):.2f}, max={np.max(result):.2f}, dtype={result.dtype}\")\n",
    "        if self.args.quantizer == \"LloydMax\":\n",
    "            logging.info(f\"LloydMax quantization - QSS={self.args.QSS}, expected range=[0, {self.args.QSS-1}]\")\n",
    "            unique_vals = np.unique(result)\n",
    "            logging.info(f\"Unique quantized values: {len(unique_vals)} values in range [{np.min(unique_vals)}, {np.max(unique_vals)}]\")\n",
    "        return result\n",
    "\n",
    "    def dequantize_decom(self, decom_k):\n",
    "        logging.debug(\"trace\")\n",
    "        return self.dequantize(decom_k)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main.main(local_parser.parser, logging, CoDec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6bfef9",
   "metadata": {},
   "source": [
    "## c) Usage within VCF\n",
    "\n",
    "### Integration in the Compression Framework\n",
    "\n",
    "MDCT integrates into **VCF (Visual Coding Framework)** as an **alternative spatial transform** to the standard block DCT (2D-DCT). Its function is to exploit **spatial redundancy** in images.\n",
    "\n",
    "#### Compression Flow with MDCT:\n",
    "\n",
    "```\n",
    "Original Image (RGB)\n",
    "        ↓\n",
    "Color Transform (YCoCg)\n",
    "        ↓\n",
    "2D MDCT (Modified Lapped Cosine Transform)\n",
    "        ↓\n",
    "Quantization (deadzone or LloydMax)\n",
    "        ↓\n",
    "Entropy Coding (TIFF, PNG, Huffman)\n",
    "        ↓\n",
    "Compressed Bitstream\n",
    "```\n",
    "\n",
    "#### Advantages over 2D-DCT:\n",
    "\n",
    "1. **Elimination of blocking artifacts**: MDCT uses overlapped windows (50% overlap) that smooth transitions between blocks, improving visual quality.\n",
    "2. **Better compression of transitions**: Especially effective on images with gradual changes.\n",
    "3. **Flexible configuration**: Allows varying block size (`-B` flag).\n",
    "\n",
    "#### MDCT Parameters in VCF:\n",
    "\n",
    "| Parameter | Flag | Type | Description |\n",
    "|-----------|------|------|-------------|\n",
    "| Block size | `-B` | int | Block size (default: 8). Analysis block: 2B×2B |\n",
    "| Color transform | `-t` | str | Color transform (default: \"YCoCg\") |\n",
    "| Perceptual quantization | `-p` | bool | Enables perceptual quantization |\n",
    "| Disable subbands | `-x` | bool | Disables coefficient reordering |\n",
    "| Quantizer | `-a` | str | Quantizer (deadzone or LloydMax) |\n",
    "| Quantization step | `-q` | int | Quantization step |\n",
    "\n",
    "#### Example Usage:\n",
    "\n",
    "```bash\n",
    "# Basic encoding\n",
    "python MDCT.py encode\n",
    "\n",
    "# Encoding with perceptual quantization and larger block\n",
    "python MDCT.py encode -p -q 4 -B 32\n",
    "\n",
    "# Decoding\n",
    "python MDCT.py decode -p -q 4 -B 32\n",
    "```\n",
    "\n",
    "#### CoDec Class Implementation:\n",
    "\n",
    "The `CoDec` class in `MDCT.py` encapsulates the encoder/decoder:\n",
    "\n",
    "- **Analysis**: Applies color transform → MDCT 2D → Quantization\n",
    "- **Synthesis**: Dequantization → IMDCT 2D → Inverse color transform\n",
    "- **Output files**: `/tmp/encoded` (quantized coefficients) → `/tmp/decoded.png`\n",
    "\n",
    "---\n",
    "\n",
    "## d) Practical Usage Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8bda14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9eee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run download_default_image.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502589b0",
   "metadata": {},
   "source": [
    "### Basic Functionality - Encoding and Decoding Parameters\n",
    "\n",
    "The following examples show how to use MDCT in VCF for encoding and decoding images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../src/MDCT.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea84a4",
   "metadata": {},
   "source": [
    "### Encoding Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33559a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../src/MDCT.py encode -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ae16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -f /tmp/encoded*\n",
    "python ../src/MDCT.py encode\n",
    "rm -f /tmp/decoded.png\n",
    "python ../src/MDCT.py decode\n",
    "python ../src/RDE.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d222cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=\"/tmp/decoded.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8280973e",
   "metadata": {},
   "source": [
    "### Example 1: Basic Compression (without subbands reordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08539c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -f /tmp/encoded*\n",
    "python ../src/MDCT.py encode -x\n",
    "rm -f /tmp/decoded.png\n",
    "python ../src/MDCT.py decode -x\n",
    "python ../src/RDE.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c773018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=\"/tmp/decoded.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c2541c",
   "metadata": {},
   "source": [
    "### Example 2: Compression with Perceptual Quantization (low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff23752",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -f /tmp/encoded*\n",
    "python ../src/MDCT.py encode -p -q 4 -B 32\n",
    "rm -f /tmp/decoded.png\n",
    "python ../src/MDCT.py decode -p -q 4 -B 32\n",
    "python ../src/RDE.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f8546",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=\"/tmp/decoded.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6506ef",
   "metadata": {},
   "source": [
    "### Example 3: More Aggressive Compression (high perceptual quantization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65421a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -f /tmp/encoded*\n",
    "python ../src/MDCT.py encode -p -q 8 -B 32\n",
    "rm -f /tmp/decoded.png\n",
    "python ../src/MDCT.py decode -p -q 8 -B 32\n",
    "python ../src/RDE.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a68356",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=\"/tmp/decoded.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42c863",
   "metadata": {},
   "source": [
    "### Example 4: Using LloydMax Quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa27b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -f /tmp/encoded*\n",
    "python ../src/MDCT.py encode -a LloydMax -m -2048 -n 2047\n",
    "rm -f /tmp/decoded.png\n",
    "python ../src/MDCT.py decode -a LloydMax -m -2048 -n 2047\n",
    "python ../src/RDE.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f03000",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=\"/tmp/decoded.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
